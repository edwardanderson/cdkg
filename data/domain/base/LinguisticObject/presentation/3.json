{
  "@context": "https://linked.art/ns/v1/linked-art.json",
  "id": "https://example.org/cdkg/LinguisticObject/presentation/3",
  "type": "LinguisticObject",
  "_label": "Textual content of \"One graph to bind them all! Linking data & apps for event-driven interoperability\"",
  "classified_as": [
    {
      "id": "http://vocab.getty.edu/aat/300027388",
      "type": "Type",
      "_label": "Transcript"
    }
  ],
  "content": "Hi. I'm Dave Duggal, the founder and CEO of Enterprise Web. I'm glad to be here with you today at CDW twenty one, to present my talk, One Graph to Bind Them All, Thinking Data and Apps for Venture and Interoperability and Automation. And I'll start by saying that, you know, One Graph to Bind Them All is a bit of clickbait, and I hope it brought you to this meeting, and created some, curiosity. But I wanna, you know, set the record straight. I am I'm not here to talk about a new form of, centralized monolith. I'm not here to tell you to burn down your, your legacy systems. What I I am here, to do is to propose the graph is actually an ideal way to coordinate end to end, processes in a distributed system in a way that traditional middleware and even cloud native tools are not capable. So let's start. So the problem statement we're going to address today might be a little bit different than some of the other talks at CDW. We're gonna focus today on business operations. And I think it's fair to say that today, in the world that's increasingly, you know, dynamic, distributed, and diverse, business operations are increasingly fragmented. It's difficult for businesses, organizations to coordinate across business silos, cloud hosts, and ecosystem partners. I don't think these are news flashes for anybody. I think this is a general experience. And, again, graphs are well suited for describing complex real world relationships. I think everyone at CDW already recognizes that, but their use has been generally limited in visualization, analysis, and interoperability of data. What we're gonna explore is the use of graphs to integrate data, applications, services, cloud hosts, networks, and physical devices. Essentially, not just look at data and properties, look at, data and functions. To look at, data and behaviors. So we're going to look at building information systems using graphs, entirely on graphs. So my company, company's no code platform, essentially makes it easy for customers to rapidly model complex distributed operational domains as a graph knowledge base an enterprise web. The scope is a bit bigger than what you might think of as a an a data fabric or a data mesh or virtualization of data, you many of you are gonna be familiar with. Here, we're talking about an umbrella abstraction that provides a unified interface for weaving distributed data and functions to a logical view with aggregated system wide entities, the index catalog of type domain objects. So a a broader scope, a a complete scope actually, allows us to take use data, to use graphs, data and functions to generate highly contextual, processes and services. So my thesis is that businesses need an enterprise web, a single source of truth across a complex distributed system. And what we're talking about here is a graph that helps organizations bring order to increasingly fragmented operations, higher level model, higher level abstraction. And this way they can share leverage, leverage shared metadata, relationships, and state to not just drive human and system discovery, but also declarative composition, intelligent orchestration, closed loop automation, and policy based management. So just think about how powerful a system would be if you actually had one pool of metadata and relationships implemented in a cloud native way that's fully distributable. So it's not, you know, centralized. It's not monolithic. It's fully distributable. And then you can actually have common pools of metadata and relationships and state information, to manage your operations. It would allow you to personalize customer experiences. It would allow you to synchronize your, operations and optimize your business transactions. So at the heart of enterprise web is our patented language. It's called the Graph Object in Action Language or BOAL, and it is a common machine readable language for non normalizing heterogeneous solution elements. And this is sort of the fundamental problem of the twenty first century, at least it's the software. But actually, since software is eating the world and everybody wants to be a digital business, it really applies to almost everyone. Is how do they connect their disparate systems, their disparate and distributed systems that are also changing very rapidly, evolving very rapidly? How How do they manage? How do they work across that? How do they connect across silos? How do they connect ecosystem partners? How do they work across clouds? How do you how do you work across this very fragmented environment where, you know, different endpoints are using different protocols and different formats and different schemas? And the answer really is high level abstraction. The user lies above this. So our language provides a graph data structure mapping properties, behaviors, dependencies, and constraints to a of of, solution elements to a graph knowledge base. So we're talking about a very rich graph, beyond data types, it's also functional types, which makes our language goal more than just, you know, a modeling tool, a domain modeling capability. It's a domain language, a DSL. It's also also gonna be modeling interfaces, so we can manage interoperability. Configuration language, so we can, you know, connect and configure, distributed, applications. And a workflow language so that we can actually use graphs to actually describe sets of tasks that are very dynamic, that they they have relationships, and they bind on bind on events and policies. So we're talking about a single language that's a DSL, an IDL, a CDL, and a WDL in one. My picture there is blocking that. So this is the conceptual architecture of Enterprise Web. We start with an upper ontology of system concepts. Right? And then enterprise web presents, customers with a baseline model that already understands, you know, generic enterprise concepts and, IT and cloud type or system types. And so we we give that to everybody out of the box. Right? We understand what people are and units are and facilities and locations and various aspects of, typical, enterprise operation. We also, of course, understand, you know, what, protocols are, formats are, types are, so that we can manage those as well. Then we have an ability for customers to model their own domain as a graph knowledge base. And, here what we're talking about is a knowledge base that not just describes their environment, but connects it to this higher level upper ontology, which includes the types that so they can actually generate implementations out of them. It can generate full blown interfaces out of them. It can actually, connect processes, can, you know, expose services using this system. So now we're talking about a graph knowledge base to model the domain connected to a rich system description of, distributed systems. And then at the bottom of this is a catalog of objects, the objects of the domain. Right? So you model your domain and then you have objects of your domain. These are actually the solution elements that are relevant to a particular customer. It might be applications, artifacts, systems, services, databases, devices. It doesn't really matter what they are. It's the things that that is that matter to that business that they need to connect. And we create make it easier for them to do that as well. So we're talking about a single a a graph approach to all three layers upper ontology to graph knowledge base, to also describing objects as so she abstract data types as, as, objects with relationships, concepts, types, and policies, which essentially map them back up to the domain, then in turn up to the, upper ontology. So but having a single language means that this could be highly efficient because at the end of the day, an object is a solution element that's mapped to graph knowledge base, which is also a graph, which is also match mapped up to the upper ontology, which is also a graph, which means that the whole thing is just a function of graph processing, and we essentially have one approach to graph processing the whole thing. That means we can do very efficient, real time, contextual processes where it might be much more difficult to do that given the latency with cloud native toolchains, which are middleware stacks. So to get into that a little bit deeper, for modeling the operational domain, first I said, we give you a baseline model out of the box. It includes generic device concepts and types. It's fully inspectable and extensible. Then customers can actually start by they can jump start their modeling by importing a model, like an XML, RDF, JSON, etcetera. They can even give us pseudo UML that might be in a Word document or a PDF document. And we can import those through algorithmic entity extraction, and map those to concepts in our upper ontology to essentially see the graph knowledge base. And we do that in seconds. And, from there, solution architects can continue by manually curating the graph knowledge base, right? They can tune it, they can extend it, they can modify it as need be for their operational domain. And another way to get model information into the system is actually by onboarding solution elements themselves because as you onboard more elements and as your as your use cases expand, you're effectively going to be expanding your domain as well. Right? So that leads to this row as you go concept. Because everything is done in graphs. Graphs are optimally situated not only for flexibly modeling relationships, but, you know, with graph, we all know that graphs can actually be modified much more easily. Static hierarchical models, right, they're easier to evolve over time. In enterprise web, everything also happens to be immutable, so we version control everything. We're actually version controlling the the objects in the catalog. Version controlling the graph knowledge base. We're also version controlling the upper ontology as we put out new releases. So everything is version controlled. Everything has audit history. And this all allows you to essentially model the use, start with maybe a narrow use case, implement that, and as you succeed, expand the use case, add more use cases, and evolve with your, domain. These are all challenges in a hard coded world that I think, many of you probably recognize. So, as we when we talk a little bit deeper into object modeling itself, now we're actually talking about how we onboard a singular, you know, it's an application, maybe it's a service, maybe we wanna onboard. What we actually already have, we give customers a catalog of a couple hundred existing, objects like mappings to Amazon cloud or Google cloud, etcetera. We have mappings for a lot of common, you know, cloud native tools and, etcetera, Kafka, MariaDB, other things like that all out of the box. But, you know, customers can also model their own, their own solution elements. And essentially what they're going to do is whether it's a code package, it could be an application, a function, an algorithm, or it could be a third party orchestrator, a controller, a system, a database. We can model adapters using enterprise web. Or if it's an endpoint like an actual service, that somebody wants to model. All of those can be modeled in enterprise web. Essentially, they're going to become typed objects, and the method is effectively the same. Essentially, there's an interactive API or a dynamic form. When you're looking to onboard something, the system essentially gonna present you with cyclically, either a UI driven wizard or interactive API that's gonna look for you to enter information that's gonna essentially progressively type the, object, the solution element that you're looking to onboard. And as you do that, the system's gonna be, in it's the type system that's gonna be interacting with the graph knowledge base in the upper ontology to autofill properties and behaviors that the system already knows Because the presumption is the graph knowledge base is in place, the graph knowledge is already in place. So we already know a lot of things about this domain. So we know a lot of things about different kinds of types. So we can auto fill the properties and generate very rich interfaces. So taking, thing things that might, onboarding things that might have taken, you know, days or weeks. We can, you know, even really complex things, and we can do it in in its towers. So we're really trying to simplify the modeling exercise itself at the graph knowledge base level as well as the onboarding level as well. Everything, like I said, is persisted in a backing store. It's an immutable log style append only storage. It's cloud native in its nature. Right? All the objects in Enterprise Web are dynamically indexed, tagged in version control. So all those things are just done as, in the background for the customers. You don't have to worry about those concepts. Essentially, we're, abstracting storage from them. So, we're also providing a process that facilitates updates and upgrades because all the objects that you onboard, all the solution elements that you onboard are gonna be version control, can anticipate that they're gonna change over time as different partners and vendors, etcetera, update their service endpoints or their application code or, or you update a technology somewhere or change a protocol. When it's time to update that, you just go back to that object, you update it, the version controlling it will take the new information, we'll put that new information, and yet we'll also preserve the history so that we know all changes to that object is the time and who made those changes. So this is what Enterprise Web looks like as a platform. Right? So we take that architecture, which I thought would be most familiar to many of you given interest in the type of people who attend a CDW meeting. So we focused on the graph architecture, but essentially we're wrapping that with the capabilities of an information system, right? There's, you know, object modeling as I just described. This is a design environment for declarative composition. So once we have objects, go to the catalog to carefully compose objects into, services, and then we can chain services into event driven processes, all with no code. Right? We're using the metadata and the, relationships, domain semantics as well, from the graph knowledge base and the upper ontology, to, compose all of these things so that we can do them with no code. And of course, the system also offers a runtime. Right? It's a cloud native, asynchronous, concurrent, so it's massively parallel, event driven system. It's reliable messaging, transaction guarantees, and state management all again included just like we abstract the storage we're actually extracting a lot of the complexity of being cloud native itself. Right? And this is a real struggle, even for advanced engineers. They're largely doing these implementing these ideas like reliable messaging, transaction guarantees, state management on a per solution basis. And here we're providing it on a platform basis. So it's available, you know, just as, that's something that everybody can rely on in the background. We're also wrapping it with platform services. Essentially we're replacing if you look at this and you'll, see a lot of common terms here, things that you would expect in a common middleware stack. We're essentially replacing the middleware stack with a set of serverless patterns. Right? Serverless middleware. That's what this really is. Instead of having different components, each have to implement and then manually integrate, and then then you have to write your code your applications to the top. Here, enterprise web says, you know what? Actually, no. Model everything declaratively, and then either the type system will attach behavior should background, or, depending on the use case, you might need to specify a certain behavior, and you then can call these functions directly. But what you're getting is this very lightweight, low latency, high performance middleware that's all served up in a cloud native cloud. So, this is, you know, our enterprise web platform is served at of fifteen awarded patents, and is deployed around the world with, you know, multiple variety of industries from telecom to life sciences. Now I'm gonna go to a concrete use case. It's an SAP use case. It's the SAP is the world's largest enterprise software company, so I'm sure many of you are familiar familiar with them or, if not, directly experienced with working for SAP. And, of course, they have great products, but like with any large company offering a wide variety of solutions, whether that's Salesforce or Oracle or, or Amazon or Google, for that matter, it's not always easy to work across all of these. Right? It's, they weren't all architected together. They have discrete sets of tools and products. And, you know, often today, we're not just connecting, one vendor's products and services. We're actually connecting them with, SAP and non SAP enterprise. So this use case is gonna explore that. So, SAP customers nowadays, like I said, have to struggle when confronted with an increasingly complex array of SAP and non SAP endpoints. So they need to integrate, orchestrate, manage, and maintain across a set of them. Now SAP has a lot of great assets, a lot of great development assets, right? They have this, thing called the Graph API, which is the One Domain Model with virtual data model. They have these TIG files called the IMG SCRO. They've got a lot of great assets that we can leverage, but in and of themselves, those assets aren't fully connected. Right? They lack the semantics to fully connect a solution in the kind of way that I'm describing to you. And solution delivery over SAP at this time still requires a mix of custom code, manual integration, BPMN workflow modeling, interface development, and complex configurations that are gonna be done with a mix of model and code. And, of course, the problem is is once you've done a mix of model and code, the model's not driving everything, and that means that you're gonna have these black holes where you don't know where things break, and you're not gonna have end to end transparency. Distributed systems, you really want that. You wanna know where things go wrong. You wanna know how your services are being consumed. Right? You wanna be able to analyze that for security. You wanna analyze that for optimization. You want to make sure that your customer is having great, experiences and that you're supporting your SLAs. So transparency is non trivial. So, let's look at a service, right? This is sort of a, you know, in the process world, they would call something like this, like a three byte kebab or a five byte kebab, which is the industry kind of jargon or describing a simplistic process. But, you know, there's gonna be a third party customer portal where somebody's gonna order a cloud application. Right? So this is gonna be a a a cloud native or a digital business use case. Somebody's gonna actually order something that is in effect, a digital product, a cloud application, And the delivery will also then be a system delivery. Right? It's gonna be it's not it's not selling jeans or a car. We're selling something that's, completely, like, visual end to end. So and then delivery is gonna be done, over, Google in this case. And so we're gonna have a third party product, and a third party delivery system, but the, ERP type services in between will all be SAP. So what we want is some sort of model connect across those, because without that model, we're gonna be doing manually integrating, and that's all we have to do. And especially since, you know, these aren't all fully connected even the SAP products aren't fully connected by a model and let alone connecting across the others. So instead of, you know, writing interfaces, doing manual integration, doing manual code, and then, of course, maintaining all that coding and recoding, integrating and reintegrating as things change, because if any one of these elements change, your solution grows. We're gonna do this all in a model. We're gonna do this with Enterprise Web. So here now you see Enterprise Web over the top. It's providing the abstraction layer I described, the middleware services, right, called the platform services, and the cloud native platform runtime. So we're not it's not gonna happen magically, right, we're gonna leverage those SAP developer assets to begin with, right? So we're gonna take those assets that I told you that were disconnected, and we're gonna connect them. We're gonna create one unified graph SAP domain, and we're gonna do it in minutes, and, we're gonna then show it to you. And, we're gonna so we're we don't have to throw away assets. That would be silly. We wanna leverage those assets, because they're good, so it it streamlines and accelerates our solution delivery. So we'd be fools not to, leverage the existing, documentation and models, that partners provide. So in this case, you know, an architecture architect can call these APIs, call this documentation, they're going to import them into the system, the system is going to do the entity extraction, and it's essentially going to set up that that initial, graph knowledge base, right? It's gonna set up your, graph operational domain. It's gonna generate generate a unified graph connected SAP domain model mapped to our upper ontology just as I described. And by that mapping of the SAP domain, which by itself wouldn't be connected to the enterprise web of ontology, where it's getting it's being wrapped essentially in additional concepts, types, and policies, which enable the declarative composition and the intelligent orchestration. From there, with, now that we've onboarded the models, we're gonna onboard these objects. Right? We're gonna onboard these, domain objects, which is the service themselves. Now at some level already, since we have Graph Knowledge Base, and we import when we imported the SAP assets, we learned about their objects, their interfaces, their properties, and behaviors. We're already gonna be able to generate a lot of this information here as far as these three services are concerned. So even a lot of that work is gonna be done. We're even gonna generate, configs and things, for these, out of the documentation that was provided by SAP. So, again, we're always seeking to leverage things that exist so that we can accelerate solution delivery and that put people in this sort of very agile graph domain model. And the last step, in this case was because we also talked about processes. Now, we could model from scratch an enterprise web a process. It's essentially an enterprise web. Processes are data flows. A data flow is, by the way, is a graph. Right? It's a natural graph. Right? An enterprise web, a process, the definition of a process is a set of tasks with relationships to events and policies. So there are the tasks then bind. It's not a static flowchart. This the tasks bind based on conditions, which is very exciting. It allows you to have, really, creative, policy based, process, processes, event driven processes that can respond to a lot of variance, a lot of what you would call in a traditional flowchart exception paths, which become very difficult to maintain, will make that much easier. In this case, actually, though, we're just going to import SAP actually had a log, called Action Logs. We're going to import the Action Log, extract the logic, and map it back up to the objects in the model, generate an event driven data flow process with all the service integration points and the corresponding UIs completed out of the box on import within seconds. Again, leveraging assets to great effect to accelerate solution delivery. If you do everything manually into enterprise web, but where you have assets, leverage them. The point here at at its core, enterprise web is a no code integration automation platform. It's completely open for federation and extension, so we're creating this environment so that you can onboard whatever you need to onboard into the domain as you describe it, and we're just trying to make it easy for you to have that domain and use and share that metadata. So, we're gonna go to I'm gonna pass the baton here into a demo. And in a second, my colleague, Bill, is a chief assistant architect. He's gonna provide the demo. He's gonna do that use case that I just described. He's essentially gonna walk it backwards. He's gonna show you the process that we generated. He's gonna run the process, which will be a mix of system steps. And he's gonna drill into the process tasks, and he's gonna show you how it was connected by metadata. You're gonna see the objects being referenced. He's Just gonna click into an object. You're gonna see all of that metadata. You're gonna see how the meta that object is mapped up to the knowledge base, to the SAP domain. You're gonna see how the SAP domain is actually mapped up to the upper ontology, and you're gonna be literally be able to walk that graph seamlessly. If you and if you have the right permissions, you could just do that as Bill Kent will do that in the demo. So I hope you enjoy the demo. I hope you enjoy the presentation . Thank you very much, and have a great",
  "language": [
    {
      "id": "http://vocab.getty.edu/aat/300388277",
      "type": "Language",
      "_label": "English"
    }
  ],
  "created_by": {
    "id": "https://example.org/cdkg/Creation/presentation/3",
    "type": "Creation",
    "caused_by": [
      {
        "id": "https://example.org/cdkg/Activity/presentation/3",
        "type": "Activity",
        "_label": "Presentation of \"One graph to bind them all! Linking data & apps for event-driven interoperability\""
      }
    ]
  },
  "digitally_carried_by": [
    {
      "id": "https://example.org/cdkg/DigitalObject/recording/3",
      "type": "DigitalObject",
      "_label": "Recording of \"One graph to bind them all! Linking data & apps for event-driven interoperability\""
    }
  ]
}