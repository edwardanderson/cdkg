{
  "@context": "https://linked.art/ns/v1/linked-art.json",
  "id": "https://example.org/cdkg/LinguisticObject/presentation/24",
  "type": "LinguisticObject",
  "_label": "Textual content of \"The Business Case for Data Management\"",
  "classified_as": [
    {
      "id": "http://vocab.getty.edu/aat/300027388",
      "type": "Type",
      "_label": "Transcript"
    }
  ],
  "content": "Hi. Greetings, everybody. My name is Mike. I'm going to present, the business case for Semantic Data Management. This is a consolidation of what I've learned over the past almost four decades of being the therapist, scribe, and analyst for the data management industry. Alright. So first, let's start off by understanding that there is a prime goal, what I call a prime directive for data management, and that is to ensure that all the users have trust and confidence that the data that they're using for their applications, is true to origin. And they should do so, without the need for reconciliation and without the need for multiple data transformations. If you think about it, and we put this in context for you, you have a right to, want I'm gonna say a right to expect the data that you're using to be true to original intent. Right? Not transformed, not, mismatched or incongruent, because it represents real things. Right? So it should be defined at the most granular atomic level to actually be able to capture the reality of the things that it's represented. It should be available when you need it, when, when your, analysts want it. They should be able to get it, themselves as they think about what they need. So it's a key part of your asset inventory along with your processes and your technologies and your requirements. The format should support, scenario based analytics. Right? You you don't want it to be stuck in the rigid technology that, you have to then kind of unravel before you can use. Right? So it should be flexible. We need it to be traceable as it flows across our systems and through our calculations and into our aggregation processes. We'd like it to be testable for fit for purpose, to make sure it matches all the logic requirements for processing as well as the quality requirements, and that should be done automatically. We'd like it to be self describing so that the meaning of the data is embedded in the content itself and reusable. Right? There's building blocks for us to put the data to work. And I will tell you that this is all completely achievable. That's completely achievable right now. Without a huge investment in technology, but it does require organizational adjustment. And in order to do that, the, the stakeholders must understand it. They must have cognition about the problem and the, pathway to solutions. And there must be leadership because, this is an act of change, and we wanna make sure that we can deal with the organizational challenges that exist. And those are the primary obstacles for implementing any new paradigm change that this represents. So let's take a look at the challenges. Right? So first we should recognize that there are, an infrastructure based on relational technologies, that are well over fifty years old. It's a lifetime in technology. That technology sometimes leads to wrong outcomes that seem like they are appropriate, but actually wind up being false narratives in today's technology environment. And that's compounded by cultural obstacles, associated with organizational change. Alright. So let's take a look at these things at in in-depth. Right? And the technology, of course, is the biggest part of it, but we have fragmentation of our technology, and we all know that. Silos exist, functional silos, process silos, business silos, geographic silos. And those silos are managed independently. And sometimes we have technology that is different in each silo. That technology is driven by proprietary data models, proprietary quality engines, proprietary glossaries, and they don't match each other. So we've done things independently, not reusable. We're looking at an environment where we have a couple pair. Right? Location based processing, where you have a column and a row, you know, expressed as a table linked with joins and keys where relationships have been constructed explicitly, and we've done stuff to optimize because we have lots of data that we have to manage. We've been copying data and moving into the silos and torturing it to death and transforming it and renaming it to make sure that it fits the glossary that drives the software that propels the data model that drives the application. That has result in a brittle infrastructure that is inflexible, and sometimes we are afraid to change it, not well documented, and it drives critical applications. This is what we refer to as technical debt, plus we have hard time tracing it as it flows through our systems, both technical lineage and the business provenance for the calculations. You combine that with concepts that seem appropriate, like the single version of the truth, which was appropriate when you only had one repository of data. But now we the reality is there are many, and we're not gonna be able to get our arms around all of the repositories of all of our functional applications across the world. So we just have to kind of accept that standard standardization of meaning is, a better strategy than trying to force fit everything into a single model or into a centralized repository. And that model itself, right, we we we understand the value of a canonical model describes relationships. Right? That's important. But having one model that describes everything, is just not practical. It would be out of date before it was finished, and you would spend all your time trying to catch up with the pace of your activity, and that is not what we're trying to do. These problems, these technological problems and objective problems lead us to the two big challenges. Right? We have, multiple identifiers. We have, codes all over our systems. We've changed and modified those for various contacts. We're we're we're having a difficult time making sure that this is the same as that, which is compounded, of course, because there's no meaning that's been locked down. And and meaning is is different when you have, front office transactions process versus a back office legal and, a settlement process. So identity and meaning, have become, incongruent. You combine that with, you know, it seems logical. Right? We try to create a a, an application for an important customer, but we do that over and over and over again, making lots of micro decisions, becomes hardwired and yet another silo. Without business rules that have been documented, they're not machine executable, and we're operating off of, next quarter spreadsheet with the pace of business, trying to push things, so we wind up doing mostly tactical activities to get us out of the fire rather than looking at the problem strategically as one that you can fix. And we have to be careful about this quest for magic solutions. Right? Everybody that sells technology always says, you know, this is the one solution you need. It might even seem like I'm gonna sell magic, but this is really just conceptual, understanding of how things work. Right? So if you look at those challenges, and now let's take a look now at the implications of those challenges. And these are actual quotes that I've been collecting over the years from people who are going through the, kind of, the data journey. First one is, we can't find this stuff. Right? We don't have a connected inventory of our assets. We made lots of copies. We, we've changed those copies. We don't have a process to prevent duplication, so we don't know where to go to get the data. So it's a big problem of even what exists and where do I get it multiplied by, the fact that it doesn't match. Right? So we have a hard time integrating it, linking it, making sure that this is the same as that, and, we miss new we have this problem of same word, different meaning, different words, same meaning. A nuance is not passed across processes, and it comes from using nomenclature as the key for its activity. I love this quote at the end, right, where it says, my projects end up as expensive death marches of cleansing, reconciliation, manipulation just to make the software work. And that story gets repeated over and over again. Because we're doing it, in our silos, we, began a local IT group to build it specifically for me. So we're not coordinating across processes, and there's conflicts and priorities and winds up, being, a bunch of, independently defined designed activities that leads to, a lack of confidence in usually in technology for being able to implement what we want. And you pull it all together and what we have is the lack of trust in the data. It's not fit for purpose. We spend seventy percent of our time doing data janitorial work just to make sure that the data is right for an application. We do that over and over and over again. I call this the bad data tax. And I've done I've done the research. Actually, I've done the research twice, once with IBM and another time with PwC to, validate that this is at least thirty percent of your operating expense just wasted. Right? And we've allowed data to lose consistency and precision of meaning. We've got it stuck in these rigid, ancient technology, environments so that we can't do what we need to in terms of automation and straight through processing. We're not getting leverage off of our expensive technology investments. We have these complex analytical models that, we're just spending all this time trying to make sure the data works and the models don't match, and we're running around doing fire drills and putting out brush fires. And mostly we're missing opportunities for upselling and cross selling and innovation. We can't understand context for legal or for finance or for marketing. And, of course, I'm in the financial industry. The regulators have a hard time unraveling the aggregates because they're trying to feed different models looking at systemic risk types of, applications. The truth is not gonna fix this by continuing to do the same thing over and over and over again. You're not gonna fix this by adopting more proprietary schemas, managing that rigid pipeline, or trying to force fit data into legacy data models that were created for specific applications. We have to look at this thing differently, which is why I focus on, these two concepts. Right? I'm not gonna shy away from them. One is semantic. It just says meaning, and the other one is standards. So these are wonderful ideas. We should not worry about the the, the dreaded o word of ontology is a fantastic Let me see if I can demystify this for you. Starts with, four concepts, four standards concepts of which is a scaffolding for everything else. Right? And the first one, the most important one is the ability to reconcile identity against a single, permanent, unique, unchangeable identifier in the cloud. You know, it's a, you know, individualized resource identifier or a resource locator. Forget what it's called. It is a ability to have a single precise granular identifier for everything to which all of the other systems get linked to. Right? So you should think of this as the Rosetta Stone capability that allows you to not have to move the data. You just link it up to its identity in the cloud. You combine that with ontologies. Right? So there there are two sides of this coin. First is, can we model precision? And and the answer is yes. We can. Right? We know how to capture what subject matter experts tell us to in the way things work, boxes and line diagrams. But the magic here is that we can express it now in standards using the triples, the other word, the gift of the Department of Defense. Understanding triples is straightforward. Just recognize that couple pair, current relational technology is location based. Right? It's a column row with tables, joins, keys, and explicitly defined relationships. A triple is a sentence structure. Two nouns, they call them subject and object, linked by a verb called a predicate. All of those things are precisely defined at their most granular level. So they become building blocks that you can then reuse for applications because they capture concepts. It's not necessary to be an expert at how to write, SPARQL queries, but, you should understand the basic philosophy behind how it works. And then, of course, the final part is business rules that are also, machine executable in, a semantic language. So rules and identity and meaning come together. You should remember the semantic trinity. Right? Identify, describe, and express. That's the goal. With those standards, we get these fantastic capabilities. Right? So the first one is, quality by math. Right? It's they're all axiomatic statements, and and if it doesn't match the structure of the ontology, then it doesn't get imported into the system. So bad data cannot get into your system in the first place. You're not running around trying to find it and clean it. It's done automatically. These are concepts. They're like tinker toy building blocks that you just kind of create and put together, and you get to reuse them application by application. So you take identity and meaning, and you add to that time, and you can express almost every context with those three things. And source is important because you want to make sure the quality of the data is fit for its intended use. Right? So this is all mostly about describing the data, not about the values. Sometimes it's critical for you to multisource or triangulate to make sure that the value is accurate as well. With semantic standards, we can and actually because it's linked to the identifier, we can track it as it flows across all of our systems, goes through our calculation engines. We can, manage our, privacy and our security concerns. We can prove to our, auditors that we know, how it flows and we have a control environment. Governance, which is mostly about quality and definition and requirements capture, is all done automatically. So governance becomes simplified and valuable. Right? It's not onerous governance. It is what do you need and let's go focus on getting it and and integrating it into our semantic environment. It's all machine readable, so humans can understand it as well as machines, and it's done on a continuously tested basis. So there's no big bang releases that you have to worry about. You can add modular components, and they're always continually tested of whether it is logically valid or of the right structure. So with those capabilities, there are kinda two things that I look at. One is why we do it, and the other one is what we do. And these kinda cross over each other. Right? And we do this for straightforward reasons. Right? We wanna operate efficiently. We wanna automate our processes. We wanna make sure that we have control over the data for privacy and for, regulatory compliance. We wanna give our data scientists flexibility to follow their intuition. We wanna be able to link up products, transactions, and customers so we can upsell and cross sell our activities. We we do that by building connected inventories, by facilitating the integration of data across our organization, and by managing the access to the data at a data point level, not a system level, a data level, so that we are ensured of privacy, management constraints. Let me drill down to this just a little bit deeper. So I think this is really the essence of the business value side of the business. Right? And we'll do this in the standard three c's of cost, capability, and control. So as I said before, this is about thirty percent savings minimum, because we've standardized meaning and standard identity and we have the entitlement control, Integration becomes simplified. We can, get rid of redundant systems and consolidate activities, and we can achieve automation. So the cost savings alone are overwhelming. But, really, we're doing this to facilitate, innovation. Right? We wanna make sure that our analysts can follow the what if scenarios that are required so we can test out ideas. We wanna be able to look at things from different perspectives, and we don't wanna be, forced to have to restructure data just to look at it from a different view, like a risk risk view, not the same thing as a legal view, not the same thing as a financial view, not the same thing as a marketing view, not the same thing as a regulatory view. We should be able to look at all of that, by asking questions of the data rather than restructuring its, its format. And then the goal is to establish what the regulators in our industry called, a control environment, which is defined, attract, with systems of record so we can comply with our obligations, so we can aggregate things on a consistent basis across our organization. So when you look at that, it's kind of an overwhelming value side. But there's a cost associated. There are challenges, and and we have to be honest about the challenges as well. Right? So let's take a look at this idea of data centric, and and I think a lot about this. I'm, like, wondering, you know, what exactly does it mean? So I stole this quote. I think sums it up properly. Right? It's not about the technology. This technology works as advertised. This is about cognition and understanding and making sure that people get the joke and believe in the possibility. Because once you do that, it becomes obvious that this is the way we should be operating our organization. In order to do that, we have to manage two critical, inhibitors to adoption. And the first one is really to full. Right? It's what I'll call in organizational inertia. Because not only do you have to have this data centric orientation of, why we have incongruence and the implications, but you have to be able to, manage the organizational challenges of priorities and politics and processes and give appropriate air cover and and allow for the infrastructure to be created, meaning coordination across your processes and facilitating collaboration. It's a big ask. We know that. But this is really the big challenge is it's not really the technology. There is some transformation costs. Right? You do have to have, triple store triple stores and and the tool sets. There is a skill set requirements. You must build the ontologies correctly, manage pipeline from ingestion through, application. So this is the this is the other side of the coin, and it's a real side of the coin. Mostly compounded by what I call the four horsemen of the data management apocalypse. Ignorance, arrogance, obsolescence, and power. And we all know, they run rampant through lots of organizations, and we have to kind of, manage this organizational challenge because we're talking about thinking about data in a different way. So we paint you a composite picture, and it starts with let's call this the infrastructure, and the most important one is this information literacy concept of understanding the problem and what it means, and why data meaning is not data processing, and why this is not a technology problem, and the possibilities of fixing this, adopting standards, doing appropriate data hygiene. You know, regardless of how you do this, whether you do a conventional technology or semantic, you have to manage the hygiene of your data. If you're going to do all that work, do it strategically. And that makes sure that we have to deal with, organizational, dysfunction and and, you know, I've been tracking data manager for a while, and I call this little g governance in data management. We're doing that pretty well. We've learned a lot about that. But big g governance of getting the organization to adopt a way of thinking, is the challenge that senior execs are responsible for implementing. There are some requirements. You know, as I said, cognition and buy in is critical. Air cover is critical. Understanding why we have a problem and the implications, being able to to think of this strategically, not just tactically, you know, fix the problem once and get it off our plate. Please, adopt this idea of the semantic trinity of identify, describe, and express. Right? Identifiers, common meaning, standards expression with an accountability and policy framework around it that, helps us with our ecosystem management. And then there are three big areas. Right? First one is the architecture. We talked a little bit about this. Right? Identity and meaning resolution, expressed in standards with executable business rules, and managing the pipeline, which is itself a challenge. Right? You have to manage it differently in a semantic world, to be able to, you know, triple ify it, you know, turn it into triples and align it with just the ontologies. The business case must be made over and over again to all the appropriate stakeholders. We have to think about them from the building blocks. Right? You know, that is identity and meaning and time and source giving us context, mathematical quality value validation, reusability of our concepts and how what does it mean to manage in a conceptual data environment, and traceability from, through all the transformations. The audit is very happy about that. The business case of the big three c's, right, cost, capability, and control, plus the language of, business in terms of measurement criteria. Right? Efficiency of use and user experience and time to market, and we can prove all this. And we spend a lot of time worrying about the measurement criteria, which I'm happy to share against the cost of conversion. Right? The inertia of our organization. This is all real stuff. Right? The physical infrastructure and transformation we have to do to map from conventional to semantic. And then there is an operating model that, is required. This is the data hygiene operating model, if you will. But I've simplified this. Right? So the first part of this is to document what exists. Build your inventory, understand the data flow, manage your lineage, then you simplify all that, authorize domains, names, systems of records, provisioning points, classification of what's important, and data architecture, capturing business concepts and translating them into data concepts. Let's not underestimate the value of this, the importance of this. Governance is required. It's gonna be light touch, but you're gonna have roles and skills and and policies and, you know, appropriate funding and prioritization management and escalation processes and all that stuff. And then how we talk about it. We talk about it differently to business, you know, time to market, use cases versus technology, which is about integration and scalability and resiliency versus control functions about transparency and traceability and auditability. So this is, emphasizing the importance of, education and messaging because buy in is the fundamental task if you're going to go in this direction. So here's some concluding thoughts. First, implementing a semantic environment can be done incrementally, use case by use case. Right? Which is that and that that would be the way you would do it, and I would be happy to talk to you about what the appropriate priorities are and how you implement that. There is a foundational level level. If the engineer does correctly, these are concepts, and and we have to be able to capture things like, obligation and commitment and control and party and role. Then you and engineering that is critical because this is the scaffolding from which we build the rest. There is some investment. It's not huge. This is not a rip and replace, but there is some investment in technology. The good news is it plays nice with all of your existing environments. You do have to make a transition, and business value is not always immediately known from the first use case, but all the rest of the use cases become a lot easier. So a little bit of patience is required. That's why leadership is critical, like finding the right sponsor, providing the appropriate air cover, you know, organizational challenges are necessary, including the right team leader for your semantic journey. And then process. Right? This is a ability to engineer, test, add, test, have policies test. Those are all critical. I will make these slides available. I did a good big Ben Franklin, cost benefit. They're both legitimate size. Right? I think the drivers are overwhelming, and this is a strategic value that I would, encourage everybody to consider. But managing organizational cohesion is not, an insignificant problem. So this is me. By all means, reach out. I'm making this course available through my friends at the Knowledge Graph Conference. Joaquin Melara is the CLL. He's been terrific in helping me get this organized. So thank you for your attention, and, good luck to you.",
  "language": [
    {
      "id": "http://vocab.getty.edu/aat/300388277",
      "type": "Language",
      "_label": "English"
    }
  ],
  "created_by": {
    "id": "https://example.org/cdkg/Creation/presentation/24",
    "type": "Creation",
    "caused_by": [
      {
        "id": "https://example.org/cdkg/Activity/presentation/24",
        "type": "Activity",
        "_label": "Presentation of \"The Business Case for Data Management\""
      }
    ]
  },
  "digitally_carried_by": [
    {
      "id": "https://example.org/cdkg/DigitalObject/recording/24",
      "type": "DigitalObject",
      "_label": "Recording of \"The Business Case for Data Management\""
    }
  ]
}