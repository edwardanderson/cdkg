{
  "@context": "https://linked.art/ns/v1/linked-art.json",
  "id": "https://example.org/cdkg/LinguisticObject/presentation/17",
  "type": "LinguisticObject",
  "_label": "Textual content of \"Taxonomies: Connecting Data with Duct Tape\"",
  "classified_as": [
    {
      "id": "http://vocab.getty.edu/aat/300027388",
      "type": "Type",
      "_label": "Transcript"
    }
  ],
  "content": "Hi. I'm Mike, and I wanna talk about how a lot of us are using taxonomies to connect data. A very special kind of data, knowledge, usually based on language, not on numbers. We still have a lot left to do if we're going to build the foundations for a new generation of semantic technologies and artificial intelligence. I haven't presented to a connected data world audience before, so let me introduce myself. I have an unusual background, including professional tours of duty as a scholar, laboratory scientist, management consultant, and technologist, which seems to baffle many of my colleagues. At this point, I've been working in AI for more than twenty years. And now I've been tech lead for knowledge graphs at LinkedIn for several years. Tech lead simply means that when no one else knows what to do some how to do something, you have to come up with a solution as soon as possible. I wouldn't have any other role. And there's a theme to my varied career. It's all about connecting language and knowledge in wonderful and scalable ways. So it's fitting that I work in cognitive computing at the intersection of human expertise and machine intelligence. Drawing on this very background, I have extensive experience looking at how both humans and machines perform the same language and knowledge related tasks. The title of this talk alludes to Perl, the programming language that was often referred to as the duct tape of the Internet. Duct tape is good because it's flexible and easy to use, but it tends to hide problems rather than fix them, and it's difficult to troubleshoot and extend. I'm seeing lots of teams trying to connect data using taxonomies as duct tape with predictably unreliable results. And this is particularly important because I see a dramatic increase in work on developing taxonomies at leading companies. If, as the saying goes, experience is a fancy name for all the errors that you've committed, then I have a lot of experience to talk about. I'd like to tell you about some of my misadventures in knowledge organization. We're all familiar with simple taxonomies. I see more and more investment in developing them for industrial purposes with each passing year. I see more publications on taxonomies and more job postings for taxonomists. I hear of more new teams and field more and more questions about how to start building a taxonomy team. But are taxonomies the best use of our time? Most of us have heard about taxonomies since biology class in sixth grade. We assume that they're important and useful even when we don't have a very clear idea of what the details are. So what I frequently see is that teams who face challenges of knowledge organization turn to taxonomies as their first choice. Unfortunately, taxonomies are rather murky territory. There's no explicit definition of them that's easily findable. There are no best practices. There are few experienced people who know how to build them. There are no reliable evaluation methods and essentially no notion of done. And since there's almost no reliable reliable documentation to fall back on, we essentially have to rely on what we remember from biology class and hope for the best. But that's not a lot to work with. So this is a classic duct tape situation. It's almost guaranteed to produce flawed results at a high cost. But we forge ahead. We build a tech a taxonomy. And it seems like every time we build a taxonomy, the same thing happens. We put a lot of effort into making it correct and coherent, then get sign off from key stakeholders. Things look like they're going well. It's almost time to move on to the next project, and there are so many of them as more people start to understand the importance of our work. But when we try to get buy in from product partners, dozens of questions come up crop up from the CEO sometimes all the way on down the line. There are a wide range of questions, and all of them seem to be theme and variations on this doesn't meet our requirements. What did we do wrong? Oh, and if this hasn't happened to you yet, it will. Believe me. And when the CEO and product leaders are breathing down your neck, it gets uncomfortable. So this situation really wreaks havoc with our schedule and with our morale too because we have so much explaining and rework to do. So part of my job is to understand what's going on and to fix it somehow. This is the classic tech lead question, why did this happen? And I find it very valuable to listen first and very carefully, to spend time understanding how stakeholders think about our very nerdy, very technical issues. The stakeholders make it sound like a taxonomy really does not meet our needs and that we screwed up. So let's look at the kinds of issues that stakeholders raise when faced with a taxonomy. I don't have to tell you that product managers ask lots of questions. They're usually worried that rolling out a new taxonomy will wreck their products, even if right now they're using very messy data. Their questions often focus on other related entities, like dog houses and dog shampoo and veterinarians and pedigrees. They sense pretty quickly that taxonomies create issues of coverage of the domain. You probably don't want to answer that this kind of information doesn't fit into taxonomy, even though that's true. You might mention, though, that there were parts of the product requirements that weren't so clear. The taxonomists slaving away in the trenches also have lots of questions. Their questions often focus on the many, many exceptions and edge cases of what's correct. They ask, where should I put mixed breed dogs or service dogs of unknown breeds or hunting dogs that are also pets. They sense pretty quickly that taxonomies create issues or accuracy of the domain. Of course, managers of all stripes have lots and lots of questions. And their questions often focus on more, better, faster, and cheaper. They'll ask, how will you make the process faster? How you expand to new domains faster? How can we evaluate the workers better? They sense pretty quickly that taxonomies create issues of scalability. And the users, of course, also have lots of questions. Their questions office focus on, why don't you say it like I do? They ask things like, why do you call them service dogs? I call them support dogs. And hunting dog, don't you actually mean a sent out? And we can see pretty quickly that taxonomies create issues of communication of the domain as well. Taxonomies rely crucially on the category labels to communicate different concepts, but different people use different terms. Given these many limitations, at best, a taxonomy might be a patch or a short term workaround. So far, we've learned a few things. Taxonomies create a range of big problems: Problems of coverage, problems of accuracy, problems of scalability, and problems of communication. But why? Why aren't taxonomies working for us? If we don't understand why, we'll just keep repeating our mistakes. But do we need to fix our communication, or do we need to fix taxonomies themselves? Stakeholders look at taxonomies as a black box. We need to open up this black box. Let's go back to the beginning for a second. Is this unexamined assumption a good one? It's starting to look like it's not, and I can see two possible reasons. Either we're not building them correctly, or we're building the wrong things. So we need to understand taxonomies better to see how well they will work for us. Taxonomies are tools for knowledge organization. Okay. My key question today though is how good are these tools for connecting data? It's surprisingly difficult to find definitions of taxonomy with clear explicit criteria. I really had to dig to go beyond a system of classification used in biology, blah blah blah. It turns out that taxonomies are built with a very specific formal framework that is based on set theory and formal logic. There's a system of interrelated conventions like those listed here that essentially define what a taxonomy is. There are many issues with these assumptions, but for the moment, let's focus on some of the practical consequences of assuming that they are useful. Taxonomies assume that there's only one kind of item in each taxonomy, for example, a taxonomy of dogs. This is just to say that taxonomies are focused. We don't find a single taxonomy that includes dogs, houses, and shampoos. And this makes sense. Taxonomies represent degrees of similarity, and dogs, houses, and shampoo are not similar. But taxonomies make it hard for us to describe other related entities, like dog houses, dog shows, and veterinarians. And taxonomies usually don't go beyond entities to describe events, processes, states, contingencies, or other things. I keep hearing that we can simply use related terms to include other entities. But related terms, as you see here, are subjective and ill defined. The unclear semantics makes it very hard to guide and validate consistent choices of related terms. Taxonomies also assume that categories are essentially labeled sets of items. For example, these are the items in category X. And labels are very often taken to be enough to describe the semantics of a category. But labeled sets are the bane of our existence. When categories have labels and no explicit semantics, it's nearly impossible to annotate and validate their members consistently. This is very, very common in my experience. Annotators most often work from labels without explicit definitions or well documented guidelines. And that means that we can't describe exactly why an item is in a category, or even what it means to be in a category, or how to validate the placement of an item in a category. Taxonomies also assume that items are in one and only one category. Like, final is an example of a setter and is not in any other category. This is the most frequent assumption for standard taxonomies. Of course, permitting multiple categories or parents is an option for extending our taxonomies. But what do we do then with double counting? If each item can appear in multiple categories, then their occurrences will sum to more than one hundred percent. And one key use case for taxonomies is aggregating data for insights. Besides, multiple parents won't help with cases like we don't know, where there's not enough information, or there's a data error. If item x is in category y has to be entirely true or entirely false, then a statement like nursery manager is in category healthcare jobs will force us to incorrectly classify professionals who cultivate trees and shrubs as health care workers. In part because of this assumption, we still don't have good methods for evaluating items that are partially correct or totally irrelevant. Taxonomies also assume that only one kind of relation exists between items and categories. In parallel to set theory, an item is a member of a category. Like Fido is an example of setter. But that means that we can't describe things like Fido is bigger than poodles or similar to terriers. The usual conventions of taxonomies make it very difficult for us to describe other kinds of relations between items and categories. The same thing holds for the relation between one category and another. In parallel to set theory, a category can be a subset of another category, like setters or a kind of hunting dogs. But cats aren't a subset of dogs, so we can't describe any relations between them. The usual conventions of taxonomies make it very difficult for us to describe other kinds of relations between categories like the ones listed here. We've learned a few more things. So now we can see why taxonomies create a range of big problems. Assumptions about items and relations lead to problems of coverage. Assumptions about categories lead to problems of communication and of accuracy. And assumptions about the nature of true and false lead to problems of accuracy and scalability. Taxonomies create problems because they're simply not the right tool for many of our use cases. And we've seen why the field is moving away from taxonomies to ontologies and knowledge graphs, because ontologies and knowledge graphs impose fewer restrictions on the kinds of knowledge we can represent. So my first lesson from all of this is that taxonomies are in fact a kludge, not a fix. We're barking up the wrong tree. And my second lesson is that build a taxonomy doesn't always mean that we should build an actual taxonomy because stakeholders often aren't clear on what a taxonomy is or on the other options that we have. So we need to understand taxonomies better to guide other stakeholders better. The good news is that we can do much better than taxonomies. In fact, we have to do much better. We're building the foundations for a new generation of semantic technologies and artificial intelligence. We have to get it right. I'd like to backtrack for a minute and ask, why did we care about taxonomies in the first place? What are we trying to get done with them? For a long time, we've thought in stark black and white terms: machine only versus human only intelligence. We assume that there are only two options available. Indeed, many AI practitioners assume that autonomous machine only AI is the best goal for the field. And human only intelligence does not scale in the ways that we need it to. In addition, today's standard practice is to keep human expertise separate and leverage it mostly for better AI, and only sometimes to leverage AI for better human expertise. But what about the Fifty Shades of Grey in the middle? Saying that machine intelligence and human expertise are the only two options is fake news. It's a false dichotomy because there are many unexplored shades of mixed intelligence in the middle. We can arrange the options on a scale from least machine participation to most. And from the beginning of the field, there have been heated discussions about whether the overarching goal should be autonomous machine intelligence or augmentation of human intelligence And now the discussion has progressed to talk about hybrid intelligence, where humans and machines work as one integrated system. So be sure to watch Frank von Harmelin's keynote about hybrid intelligence, and let me wet your appetite with a taste of what he'll be talking about. Hybrid intelligence refers to systems where humans contribute insight, creativity, strategy, and qualitative evaluation that machines lack. And machines contribute speed, thoroughness, strength, comprehensiveness, coordination, and reliability that humans lack. That is, we're looking for systems where we get the best of both human expertise and machine intelligence. And what is hybrid intelligence like? It's like the situations where humans and machines do the same task at the same time. Humans and machines interact in real time. This is like collaborative AI. And for that, we need explainable AI. Machines learn from humans and humans from machines, which I call reciprocal learning. And this isn't science fiction. There are cutting edge products with hybrid intelligence already available on the market, like adaptive machine translation, where the machine adapts translations and style in real time according to human input, and humans can learn from the machine's consensual translations as well. We strategically choose the right intelligence for the right parts of each problem to get the best of both. We trust the machine based on understanding and monitoring its reasoning. Of course, we need lots more research to understand better what humans do best and what machines do best in these kinds of hybrid intelligence settings, and this will allow us to partition and assign tasks to achieve the best of both. But it's already clear that for hybrid intelligence, we'll need knowledge in different forms that both humans and machines can use. So be sure to watch Gadi Singer's keynote here about levels of knowledge. And again, let me whet your appetite with a taste of what he'll be talking about. Goddy makes a very significant point. We don't need to choose between deep learning models and symbolic knowledge. We'll need both and more! Neurosymbolic systems are starting to explore this space. Gotti talks about three levels of knowledge, instantaneous knowledge that's directly available in an AI system in the form of embeddings or models, standby knowledge which requires little extra processing and is slower than instantaneous knowledge. But it's applicable to more situations, and it's probably formulated into some standardized representation. Unless he talks about retrieved external knowledge, which is external information that is probably temporarily relevant and often shows up in the form of free text. So let's leverage the concepts of hybrid intelligence and levels of knowledge to articulate more precise goals for knowledge organization and connected data. This way, we'll have a clearer direction to lead us beyond building simplistic taxonomies. Again, we've learned a few more things. Now we can see why we need to move beyond taxonomies and duct tape. We need different forms of knowledge, not just taxonomies or just models. We need to work toward hybrid intelligence, not just machine intelligence. And we need to enable human machine communication with clear semantics. For hybrid intelligence, we'll need Godly's standby knowledge in place of simplistic taxonomies. And how can we get there? Let's make a to do list. First, we need to understand what are more reliable building blocks than taxonomies. And the first of those is what I call concept catalogs, List of distinct important concepts in different domains, along with different ways of expressing them, as you can see in the table below. They have many advantages over taxonomies, and possibly the biggest advantage is that they reduce subsequent processing and human review, often by a factor of fifty or more, because there are often fifty or more different textual forms for the same concept. So with that, they dramatically increase recall for search, instances for machine learning, and reliability of insights and analytics. Concept catalogs are useful whether you build taxonomies or not, and I suspect that they account for most of the ROI that we get from building taxonomies. We're all newbies, but biologists have been working with taxonomies for more than three hundred years. They've learned a few useful things from all of that experience. One is building what they call identification keys, which are essentially feature arrays that constitute definitions of species. They are a list of distinct important features and values for each species. We need something very similar for concepts generally, not just for species. This is very similar to what AI engineers call a feature space. There are lots of advantages of this over taxonomies. Categories are output, not input. We can combine the features in different ways to make different kinds of categories, it's not restricted to one entity type, and the features are explicit and accessible to algorithms rather than hidden inside human definitions. Another building block that we have to talk about is another kind of feature space, one that I haven't seen deployed in recent work. But feature spaces I just mentioned for concepts usually focus on things or entities. This one focuses on defining relations in a similar way. And of course, this has many advantages over taxonomies as well because taxonomies have very few relation concepts, kind of, example of, things like that, and taxonomies focus only on categorizing entities. Other knowledge organization methods also describe events, actions, and contingencies with relations like agent, cause, instrument, manner, temporal order, etc. And we've seen that sets of well defined conceptual relations already exist. They were developed for artificial intelligence the first time around, last century. These are epistemological assumptions, assumptions about the form and nature of knowledge, in particular about the role of different notions of truth. One very key assumption is that assertions are either entirely true or entirely false. There are no other options in any circumstances. So if item x is in category y has to be entirely true or entirely false, then a statement like nursery manager is in category healthcare jobs will force us to incorrectly classify professionals who cultivate trees as healthcare workers. The most important change here, as advances in machine learning and deep learning have shown, is to move from right wrong present absent binary truth values to continuous confidence scores that represent likelihood instead of absolute truth. So if x if item x is in category y is no longer entirely true or entirely false, then we can talk about multiple parents and use case or context dependent confidence scores for category assignment. For example, in the context of babies in hospitals, nursery manager is likely to be a healthcare position. In the context of trees and shrubs, nursery manager is likely to be an agricultural position. We can make category assignment context dependent, which is very, very hard to do with taxonomies. All these building blocks will allow us to accumulate knowledge and connect data by using statements that have explicitly defined semantics, what I call next generation knowledge graphs. Next generation because today's knowledge graphs do not always use concepts with explicit human readable semantics. And, of course, there are many advantages over taxonomies for these. Some of them are things like describing knowledge of events and of relations between statements, not just entities. And knowledge graphs aren't restricted to one entity type, and they enable more kinds of reliable inference. Knowledge in this form will provide a more reliable foundation for the next generation of semantic technologies and AI. So once again, we've learned a few more things. Now we can see why we need these building blocks: concept catalogs, concept models, explicit relation concepts, more realistic epistemological assumptions, and knowledge graphs. But how can we get there? We need to shore up our foundations to reach these goals, and I see significant issues at the base of our efforts. We have to move beyond believing knowledge creation for AI in the hands of naive, novice, non practitioners. We need systematic training programs to create essential talent. We don't have them. I've built taxonomy teams and crowdsourcing programs. I can tell you how very, very hard it is. We have to start with fundamental questions like, do we need taxonomists? What do they look like? Where can we find them? We need to explain this to managers and executives to fund the work. We need to explain this to HR to help us find and cultivate talent. Once we have the teams, what's the best way for them to work? We simply don't know. But we do know that we have to move beyond simply improvising. We need industry best practices to follow. We need industry backed processes to ensure reliable results, and we don't have them. Once we have a clear idea of the best ways for our teams to work, how can we help them? We don't want them to work independently on one item at a time in random order, slowly and manually, like a sculptor crafting a tiny statue. We have to move beyond crafting to manufacturing knowledge. We need tools to design and validate knowledge. We have to have tools to ensure reliable results at scale. We don't have them, and spreadsheets just won't suffice. To make semantic technologies really thrive, we need all of these things: better building blocks and taxonomies, more better trained professionals, explicit best practices, and AI tools for design and validation of knowledge, not just for storage and display. Let's create together a better foundation for the next generation of Symantec technologies and connected data. Thanks for your attention.",
  "language": [
    {
      "id": "http://vocab.getty.edu/aat/300388277",
      "type": "Language",
      "_label": "English"
    }
  ],
  "created_by": {
    "id": "https://example.org/cdkg/Creation/presentation/17",
    "type": "Creation",
    "caused_by": [
      {
        "id": "https://example.org/cdkg/Activity/presentation/17",
        "type": "Activity",
        "_label": "Presentation of \"Taxonomies: Connecting Data with Duct Tape\""
      }
    ]
  },
  "digitally_carried_by": [
    {
      "id": "https://example.org/cdkg/DigitalObject/recording/17",
      "type": "DigitalObject",
      "_label": "Recording of \"Taxonomies: Connecting Data with Duct Tape\""
    }
  ]
}