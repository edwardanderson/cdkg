{
  "@context": "https://linked.art/ns/v1/linked-art.json",
  "id": "https://example.org/cdkg/LinguisticObject/presentation/5",
  "type": "LinguisticObject",
  "_label": "Textual content of \"Thrill-K: Rethinking knowledge layering and construction for higher machine cognition\"",
  "classified_as": [
    {
      "id": "http://vocab.getty.edu/aat/300027388",
      "type": "Type",
      "_label": "Transcript"
    }
  ],
  "content": "Greetings. I'm very pleased to be here in CDW twenty one and talk to you, knowledgeable people, about knowledge and how we should rethink it, restructure it, and prepare it for a better AI. The last decade has been phenomenal for AI, primarily because of deep learning. But there's a next wave that is coming. And whether use system two definition that Yoshua Bengio is doing based on Kanban's or use the DARPA definition of the third wave of AI, there's something new that's coming. AI that is more cognitive, that has better understanding of the world, that has higher intelligence. And this is going to be done through a combination of components. It's going to have neural networks in it. It's going to have symbolic representation and symbolic reasoning in it. And, of course, it's going to be based on deep knowledge. And when we have it, the value that is provided to individuals, to businesses, would be redefined and much enhanced compared to even the great things that we can do today. This will require new architectures to implement it, which we'll talk about later on. And with all that coming together, a new human centric cognitive AI is about to arrive. I mentioned deep knowledge. What do I mean by that? If you look at the nature of recognition versus higher level cognition, they are very different. In recognition, there's a world out there with relatively shallow data. If you look at pixels, you just have their location, the color, their intensity, but the data is relatively shallow. It's continuous. It's differentiable. And you need deep learning and other methods in order to structure it, find what is the meaning of that, and then make it into knowledge. Cognition is different. High cognition requires to to understand a very deep structure of knowledge. Let's take the example, is grandma well? In order to pass and understand what is grandma, what is this particular grandma, what is expected in any particular age, what's the history, and many other things. What is relatively well for this particular grandma. There's so much knowledge that's in there that all comes forth with a simple question. So deep knowledge are knowledge constructs that allow an AI to continuously acquire new information, organize its internal view of the world, comprehend the meaning of grandma and well in context and reason on its knowledge. Language models are great, and they are able to fill in word, generate new statements, and in them, there's a lot of knowledge. There's statistical information, of course. There's a lot of factual knowledge, and there even some common sense knowledge. And you can see it in some of the benchmarks like the natural questions or trivia QA, where models like t five that were trained through masking and other methods are able to give pretty good results. And in addition to just having those direct ways of assessing how much knowledge is in there, you can enhance it. For example, the work that was done in Eugene Choi's group on Atomic shows that you can extract from GPT three a lot of common sense, information and enhance a knowledge graph by ten x from common sense information that is within a large model, a GPT three. And GPT three by itself, by being prompted, can give you some really nice common sense answer like x starts running so x gets in shape and so on. So overall, it's good. Language models are one of option for good knowledge models. There's also some additional value that has been quoted on why there might be a very good knowledge model because, there's no schema engineering, there's no need to have preset relations and also there's no need for a person, for humans to provide supervision. So, are language models great knowledge models? And the answer, I believe, is not. Language models are not great knowledge models, and it's true both on the effectiveness, which is how well they perform, as well as their efficiency, which is how much compute do you need in order to perform. And let's take the same t five and the benchmarks that we just show, very good performance in. When you integrate retrieval, such as in RAM or RAG or more recently infusion and decoder, you can get a much better results like going from thirty six point six to fifty one point four on the actual f one or the exact MET scores. And you can do it with a much smaller model. By using information, in this case, that resides outside and effectively bring it in, you improve both efficiency and the quality of the result. Well, you're saying that language models are performing very well as a repository of knowledge, so what's the problem? Well, they were not designed for that and even though they do well, we need to think about what is really the optimal way of representing knowledge. And there are some basic limitations in the representation and other aspects that make language model good but not great for the task. And we should remember that sometimes there's so much information learned in those language models that we can extract and enhance dedicated knowledge models. But by themselves, there are several shortcomings, and let's look at what those are. So what makes for a great knowledge model? I would say five areas of capabilities, scalability, fidelity, adaptability, richness, and explainability. Let's talk a bit about each of them. The scale of information that we're dealing with is very high, and you can see that if you look just at the sizes of the recent models. How do systems deal with this tension? On one hand, you want to have the largest scale possible. On the other hand, you want expediency. You want the ability to do it in a very cost effective manner. There is a way that systems deal with that, and that is by creating tiers or a hierarchy. You want to differentiate between things that you access every tenth time to maybe items that you access every ten trillion times. And by providing this hierarchy such as in a computer system, you are able to separate the closest thing in the computer system. It would be within the registers or the cache. Can be easily accessible. There's a small scale, high cost, but you get it when you need it immediately. And then as you go to further and further tiers, you have a larger scale, more capacity. The speed is lower, and the cost is lower. So by having a full hierarchy system, you can have the scale of the largest tier, but you can do a much shorter access time and better cost than with a single tier. And many systems in nature are operating in the same manner. Let's take an example from a completely different space. Energy gets to our cells by transforming ATP to ADP, and it's just there. How do we get this energy? We get a glucose circulating in the bloodstream. So there's lots of energy going around but still needs a little bit of processing to become available. But all this glucose circulating is not enough. There's storage, there's backup, and that one is glycogen or others that is sitting in liver, muscle cells, fatty tissue, and can be turned into glucose. But there's the external, the largest tier is of course the outside world where you have all this energy that can be consumed, digested, and then turned. So the idea of having a tiered system is one that is in all environments and settings, which require a huge scale with very fast access. Another area is the richness of knowledge. The ability to capture all the complexities, all the relationship in both in the language world as well as in other modalities. And this is something that I'm, invited to read in a blog that I published on the dimensions of knowledge. But just in a nutshell, there's knowledge about the world that needs to be captured, and it could be descriptive like taxonomies or ontologies and and property inheritance. It could be either language or it could be a three d point cloud about some some, assets, some physical objects that you capture inside. The second is ability to capture models of the world. Causal models, procedural models, physical models, how things are related and moving in time, in space, in progression. And finally, scripts and stories. It's not just things that are point. There are complex story that we tell ourselves that we know things about the world which needs to be captured in this form. And then there's the meta knowledge, context, source attribution. So if you read something in a, in a magazine from the Newsstand or you read it from the, the New England Medical, Journal of Medicine, you will treat it differently because you understand the attribution to the sources. And then there's values and priorities which are so important as part of our knowledge structure. When is something more applicable? What's the value that we put on it? And then finally, concepts. Concepts are the most important construct that we use as humans to think and build views of the world, and concepts are the one that cutting across all those views. The next area is adaptability. A knowledge model must work with multitude of data sources, types, and update rates. So if I'm a dentist with a small office, I want to be able to work with my patient's information and be able to update it quickly and be able to have different types of information in there. If I'm a financial institution, it's very different types of data. Also, the rate of change and update of the model is very important. The model need to change as fast as the relevant part in the world changes. So if it's about tracking where people live and what's their phone numbers, that's one rate. If it's tracking the latest earthquake in California, it's a different rate. And there's no path where going through a retraining or even fine tuning with new data can refresh as quick as the world changes in some of those cases. The next area is explainability. When an AI interacts with humans, how can the AI explain itself, be interpretable and communicate in a very natural manner? And this is better structured when you have an explicit, intelligible source of knowledge. For one, all the structure is built in a way that is transparent. Whether it's a taxonomy or other relationship, it can be explained more simply. It also have all the constructs to do what if analysis counterfactual in a way that can be mapped back to this explicit structure. And finally, it gives a better foundation for a human AI communication where information can be exchanged, adopted, integrated, and communicated back. Finally, fidelity. Knowledge models must retain information in a form that allows faithful reproduction to the origin, whether it's facts, attributes, relationship. When you store them in a knowledge graph, you can store them in a way that is true to source. You can also store them in a way that is not dependent on statistical occurrence. So whether it happened once or it happened multiple times, you are much less sensitive to catastrophic forgetting or other types of decay. And also because you have the full structure, because you have the sources, you can diminish some of the effects of training based bias. We spoke about all those principles of having a great knowledge model, but how does it translate to an actual architecture that can support the next wave of AI? And I would posit that the architectures need to have knowledge and information at three levels. It can do more, but three levels is the necessary and sufficient partition. So I call it three levels knowledge or it sounds phonetically like thrill k. And the first level is for the most immediate knowledge, and that knowledge is, let's call it giga scale. And it should sit in the newer network. The next level of knowledge is the deep knowledge base. So this could be a knowledge graph, for example. This is where you have intelligible, structured, explicit knowledge. And this one could be at the terror scale. And this is available whenever is needed by the neural network. And finally, there's the world information. And the world knowledge or world data is considered to be zeta scale. You've got things today in terms of the flow of information that are reaching that level of ten to the twenty one. And we need to plan our system for the Yetta scale, the ten to the power of twenty four. So we have those three levels of knowledge, The immediate, the one that is associated in the knowledge base, and the one that is supporting out there in the world. How do we put it together as an architecture? So how does the three k architecture look like? It has those three elements. It has the neural network with a lot of knowledge within its parametric memory, and simple flows could just go from input through neural network to output. But it also has the knowledge base, structured, explicit, intelligible knowledge base. So when needed, you can have the extraction into the neural network. And I'm saying reason because there's not only the symbolic representation which is in the deep knowledge base, but also the ability to do symbolic reasoning. And then, since you cannot have all the information of the world inside your model updated at the right rate, there needs to be access to the outside world and all the corpus of data, documents, images, earthquake information, financial, everything that's happening out there based on the application. And there needs to be the retrieval mechanisms, obviously, but there also needs to be a knowledge acquisition that continuously updates an ever growing consistent view of the world within the machine. And this is how we can avoid going to some of the shortfalls of handmade expert systems of the past. So how will this new AI look like? What is this new cognitive AI that will emerge? Well, you have to imagine beyond statistical correlation, beyond the type of things that we are very impressed by today. You need to imagine an AI that actually understands language by understanding concepts and relationship, not just predicts the next word or the next phrase. You need to imagine an AI that is inherently multi sourced so it can converge multiple sources into its knowledge. And multi model, because the world around us is multi model and rich. It integrates common sense knowledge, and common sense knowledge is the basis for making reasoned intelligent decisions. It can adapt to new circumstances and new tasks because the data and the knowledge is not structured for a particular task, but it's there with all its richness and expressivity to be used for new tasks. It explains itself and communicates better based on what we discussed earlier. And importantly, it is more robust and customizable. For the long tail of use for AI, the AI needs to adapt to particular environments, to your car, to your home so that it learns the specifics, it builds it into its knowledge, and it can interact with you in the most appropriate way for you. So those competencies together create a anthropocentric cognitive AI that can be achieved only if we use knowledge underlying, which is explicit, intelligible, and well structured. So what is needed to make cognitive AI a reality? Well, it takes more than a village. It takes the whole community to do it. And some of the things that are required are the capabilities to access and to mine diverse sources of knowledge and be able to bring them into the knowledge model. We need to have strong semantic parsers and knowledge representations for all this diverse multimodal knowledge. We need to have hardware and software that is able to do all this, hierarchically, on the fly, in a cost efficient manner. We need to be able to have some apps that are really showcasing this to drive the need and make all the necessary improvements on those workloads. And finally, I expect to have a new marketplace created since this is the age of knowledge emerging. Knowledge structure or knowledge basis can be sold, communicated, and used as other precious resource that we have around us today. We are doing our part of this within Interlapse at my emergent AI research organization. We are looking at multiple aspects of this, including NLP, multimodality, common sense reasoning, neuromorphic computing. And this is just an example of demonstrating the match that is being created between a word being addressed by the language transformer, part of the image that's corresponding, and there's also a data structure that is mapped into that. And this work is featured in visual comic leaderboard and other places. Let's bring it all together. So when is it going to happen and how is it going to look like? I expect that it will take about the same duration as deep learning took if you compare two thousand twenty one to twenty eleven. So this year, cognitive AI is still a nascent technology. By twenty twenty five, I expect it to be already in some commercial use. And by the end of the decade, I expect it to be a mainstay. And Thrill k promises to be the blueprint of how it's going to be implemented, And it needs to bring together new network with symbolic representation and with symbolic reasoning. It needs to be able to adapt and discover information from the outside world so it has a continuously growing knowledge base. It has to be able to provide support at scale to a diversity of users as well as usages through its flexible knowledge structure. And it's gonna build around deep knowledge that is conceptualized, multimodal, ontology based, and it's ready for the unfolding future. Thank you very much.",
  "language": [
    {
      "id": "http://vocab.getty.edu/aat/300388277",
      "type": "Language",
      "_label": "English"
    }
  ],
  "created_by": {
    "id": "https://example.org/cdkg/Creation/presentation/5",
    "type": "Creation",
    "caused_by": [
      {
        "id": "https://example.org/cdkg/Activity/presentation/5",
        "type": "Activity",
        "_label": "Presentation of \"Thrill-K: Rethinking knowledge layering and construction for higher machine cognition\""
      }
    ]
  },
  "digitally_carried_by": [
    {
      "id": "https://example.org/cdkg/DigitalObject/recording/5",
      "type": "DigitalObject",
      "_label": "Recording of \"Thrill-K: Rethinking knowledge layering and construction for higher machine cognition\""
    }
  ]
}