{
  "@context": "https://linked.art/ns/v1/linked-art.json",
  "id": "https://example.org/cdkg/LinguisticObject/presentation/11",
  "type": "LinguisticObject",
  "_label": "Textual content of \"Introducing D3FEND: A Knowledge Graph of Cybersecurity Countermeasures\"",
  "classified_as": [
    {
      "id": "http://vocab.getty.edu/aat/300027388",
      "type": "Type",
      "_label": "Transcript"
    }
  ],
  "content": "Hello. Connected Data World twenty twenty one. My name is Peter Kaloroumakis, and I'm happy to get to present the defend project to you today. A little background on me. I work for, MITRE Corporation. We're based in the United States, and we focus on, research and development problems for our sponsors, primarily, the government. Before I came to MITRE, I worked in commercial product development, and I, designed and built, malware detection products, for network security purposes. So today, I'm gonna give you, an overview of sort of the motivation behind this project, what problems we were trying to solve. I'll talk about, what we built, a little bit on how we build it, and then also talk about how some people are using it to help better organize their cybersecurity defenses. So let's get started. So first, I wanna get into the motivation for this project. And before I start talking about defend, one of the things I have to orient you to is another MITRE project. It's called MITRE ATT and CK. MITRE ATT and CK was a is is a very popular framework for characterizing, what specific things, cybersecurity adversaries are doing when they break into a network. This model was built by MITRE over a number of years and publicly released, and it's really taken the industry by storm. And the result effect is that when when cybersecurity products are able to, detect something bad, they characterize it using terminology from this MITRE ATT and CK project. So, once that was, deployed, sort of it got out there, it became very successful, a sort of natural question arose, which is sort of, could you describe what cybersecurity defenders do and as much fidelity as we, describe the cyber the attackers? So we basically proposed this project to help organize the defensive space the same way that, MITRE had organized, the offensive space. So this defensive space is huge. And if you think about it in two main buckets, first, sort of technical policies. There are thousands of these technical policies which describe how cybersecurity protections can be applied to IT infrastructures. And, you know, there's a lot of material there. The top image at the right is sort of documents that describe how to do this grouped by the general, sort of domain. And in each of those documents, there might be hundreds of recommendations or requirements that people have to implement. The other big component of this space, the other major bucket is, cybersecurity vendors. So the cybersecurity marketplace is pretty large. It's a pretty big market. There are thousands of these vendors. Some of these vendors have multiple products, and some of those products, performed dozens of discrete functions. So this really quickly gets into, a high dimensional space that's difficult to manage if you're, you know, organizing your your defenses and you have to keep track of all of this information. So in order to address all of this complexity, we wanted to build a conceptual model to help organize this space. There's a lot of challenges with trying to do this, particularly because it's such a complex and nuanced space. One of the challenges specifically with cybersecurity is the amount of complexity and nuance in all the terminology that's used. And one of the things we asked ourselves was, how do we know if we were successful in building a useful model? We felt like if we could use the same model for multiple target audiences, that would give us some indication that we hit that abstraction or semantic sweet spot, if you will. So imagine three sort of target audiences. First, cybersecurity architects who are managing these complex portfolios. They really have to understand what specific functions all of these, products and offerings they're purchasing, do in great detail. Another target audience is what we call adversary emulation, where they're doing a pen test on a system, and they have to really understand how these things work in order to have a successful , useful pen test. Imagine a third audience for this. Let's say a cybersecurity investor who's trying to decide whether or not they should invest in a product. They have to understand what problem is being solved, has that been solved before, and is this being done in a new and novel way. Right? So we felt like if we could address these multiple audiences, that would give us some indication we were on the right track. So we set about building this, and three years, in the in the making with a very small team, we put together what you see today. We call it the defend knowledge graph. You can go to defend dot mitre dot org to browse the graph, and it renders portions of the, graph in the underlying model for people to start to use it. It's very early stage, and there's, some rough edges, but we felt like it was at the point where it made sense to open it up for collaboration. We built the graph by, analyzing lots of open source materials that explain how cybersecurity technologies work in detail. This information is very difficult to get, but we found a dataset that was sort of hiding in plain sight. And it didn't look like anyone else had actually systematically analyzed this corpus before. And these were, patents that were filed by these cybersecurity vendors that explain how their product works or what specific problem it's going to solve. There's a lot of diversity in the patent corpus. And for us, the challenge was how do you take a twenty or thirty page document and turn it into two, three, or four words that really crisply explain what it's doing. So we developed a methodology which lets us systematically do that, and that's part of how we built the the overall model. The picture you see at the top left is the most prominent taxonomy inside of defend. Those are the defensive countermeasures, of course, arranged by, type hierarchy. And what we did was we render it as sort of a tabular view in order to get folks interested in the content that's embedded in the graph. We also want people to use this graph to do more sophisticated modeling, and we built it using standard ontology tools in order to support those use cases. One obvious first use case is, okay. Now that I've got these defensive countermeasures identified, what offensive techniques are are those going to address? So you see this picture of defend connected to attack, with these red lines. And then you see this call out in the middle here with this idea that we call digital artifacts. So instead of just directly relating the defensive techniques to the offensive techniques, we do it through inference and reasoning through this intermediate model. And I'm gonna talk about that in much more detail on the next slide here. So what you're gonna see is this sort of cartoon view blown up with specific examples of the types of information, we're tracking. So, the same view, you've got attack on the left, defend on the right. And in the middle, you see what we call the digital artifact ontology. So this is describing all the sort of basic computer science concepts, that someone taking computer science one zero one might be learning about. And, surprisingly, we didn't find a model that existed, that met our needs to for cybersecurity purposes. So we ended up having to take a lot of basic computer science terminology and make it a bit more specific, because at the end of the day, a lot of times, the attackers are abusing functionality in the computer, and we end up needing to be more precise about what specific functionality they're manipulating. So you see on the left, a few of these offensive techniques, exploitation techniques, and then another exploitation technique called, process injection. And and then on the right, you've got this defensive technique process code segment verification. And both of these are mapped to this intermediate concept called a process code segment. And the relationship on the offensive side is that these techniques are modifying this concept, and then on the defensive side, you're verifying this concept. You can see that a process code segment is a type of code segment, which is a digital artifact. And then you see some object property relationships. For example, a process running on your computer contains process code segments. The process originated from an executable binary file, that contains code segments. And when the process is running on your system, it loads those executable, parts of the file into memory and then executes those. And then sometimes those are the parts that attackers will overwrite with code that you don't want. So if you wanna check the integrity of your processes in their memory space, you might try to verify process code segments. So once we have those definitions defined, we can then infer that this one defensive technique might detect this particular offensive technique, without needing to directly declare that. And because of the amount of information we're dealing with, this ends up being a much more scalable, manageable approach that lets you reason about, the the the whole graph, rather than trying to manually go through and map everything, accordingly. So this is sort of, an advancement in the state of the art for us, which is, to to do these sorts of things by inference instead of manually mapping things one to another. So next, I'm gonna show you what this information looks like in the actual tool. So if you go to defend at mitre dot org, you can, load up, the home page, and you'll see this countermeasure technique taxonomy that that you see here. Across the top, we have what we call defensive tactics. Those are sort of the maneuvers that a defender can perform in response to adversary activity. And then beneath that are what we call defensive techniques or countermeasure techniques. These are, the the highest order ones at the at the second level and then, more specific types of of the technique as you go down the column. So user behavior analysis has more specific types of user behavior analysis, and process analysis has more specific types of process analysis. One of which is is the example I gave in the slide, process code segment verification. Right? And this number we're showing, we found six public references that indicate there are technologies that do this. So we believe it's worth including into, the knowledge base. So if I click this, you get, what we call the knowledge base article. This is all encoded, in the ontology. And there you have a crisp definition of of this concept. We wanna be able to ask a vendor, do you do this? Yes or no? You get an explanation of how this works that's developed by reading all of the references at the bottom of this page, and and then our subject matter experts basically summarize those. And they also add a a section on consideration. So, in this case, with this technique, they're talking about potential false positives and false negatives. Then, once we specify what this technique is doing to what specific digital artifact, we can then infer what are the related offensive techniques that we might care about. Now this, this table down here is sort of a a miniature, attack table. So if you go to attack dot mitre dot org, you'll see the full table, which has, around five hundred of these techniques. In this case, we're selecting only the relevant ones for the user to, review and determine, okay. Will this defensive technique, protect me against, these offensive techniques? And then the semantic relationships go both ways. So some of how we're doing the inference, takes into account, hierarchy and, the type hierarchy within the the artifact definition. So if a higher order concept is interacting with a digital artifact, then that flows down to the lower order concepts as well. So in this case, we're showing if if you hover here, you can see the relationships on the offensive side. Process hollowing is modifying a process code segment, but in this case, credential API hooking might modify or may modify a process code segment. So a lot of times in cybersecurity, you're dealing with maybes, and, we've at least come up with a systematic way to describe those sorts of scenarios. And then down here is the references we used to develop this article, and you can go click those and see the in this case, this is a particular patent that it links to, and you can see, what we read to basically develop this article. Right? There's a number of other things you can do with the user interface. You can look up topics by offensive technique or defensive technique with these two search boxes. So if I wanna look up a defensive technique like dynamic analysis, I can do that here, and that'll take me to that page. Or I can look up the offensive technique. Let's say I wanna look up rootkit. What do what do attackers do when they install a rootkit? Well, if you look at this graph, we sort of codify that, and the offensive technique is in the middle. Some inferred defensive techniques are on the left, and then the relevant digital artifacts are on the right here. And we're showing that this offensive technique might modify kernel modules, shared library files, the kernel itself, or firmware on the system. So, then we infer because these defensive artifacts are interacting with those that they might detect it or you could deceive this offensive technique or you might harden against this offensive technique. Right? And then you can click on any of these boxes and get definitions. So what is a what is firmware in defend? Well, if you click that, it takes you to this page, which has a definition and additional relationships. In this case, it's showing you firmware verification, might, verify firmware. And then there's, some specific offensive techniques that attackers do to modify firmware. And in this case, we're showing different types. So you see, there's firmware, but then there's specifically system firmware as well. So some offensive techniques modify your system firmware, and some of them might modify, peripheral firmware, for example. So that's a quick spin through the user interface. So I wanna talk a little bit about how we name these things. Basically, the methodology I talked about earlier was is pretty straightforward, but it, kind of embarrassingly took us a long time to figure this out. We simply describe it along two dimensions of specificity, the noun and the the verb. So we we say the the digital artifact, the noun, or defensive action, the verb. So, there's three examples here. The least specific example would be segment analysis. And then as you move up to the right, we get, the most specific process code segment verification, the example I gave earlier. Verification in this case here is we're saying is a more specific type of analysis. And the reason we took this approach was we wanted multiple teams within an organization to be able to use the same, framework. If you have someone working in acquisitions, they may not care too much about the specific the most detailed example of, let's say, file analysis. They just wanna track whether or not they have a file analysis capability or a process analysis capability. But if you have a practitioner, they might want to know about all the different ways you could do file analysis or process analysis. And by having that taxonomical approach, it lets us address both technical and nontechnical users and then capture metrics accordingly with the same language framework. Right? So I'll talk a little bit here about how people are using defend to answer questions about their cybersecurity posture. So in this example, we took a specific threat. It was, identified in this threat report. You can see the link there. And then they wanted to know, would we have had any protections against this threat given these three specific products that we purchased? So what we did was we took the threat report, and it was mapped to MITRE ATT and CK in terms of the offensive techniques that the adversary was using. So you can see in this attack matrix view on the left, for initial access, they executed a supply chain compromise. For persistence, they installed a scheduled task job and a boot auto start execution script. And then what we did was we took the defensive products and broke them down using defend and identified what they were doing. So of these three products, they were doing some hardening techniques, some detection techniques, and some isolation techniques. And then But they were not part of these three products' capabilities, so that's marked as red and purple. And then we step through the rest of the attack, and we had some capability in this area. So that was marked amber and then red in this other area. So the result was that you get these sort of higher level insights about, where you might wanna make your investments. You might wanna, in this case, make your investments more in application hardening, platform hardening, and operating system monitoring because you don't have anything there. Now they did have some capability here, but here's a case where, everybody's sort of different. If you're in a well resourced environment and you wanna add diversity and depth to your defenses, you might actually make additional investments in this area, to add diversity to your defenses, or double up on certain types of analytics, for example. But if you're in a resource constrained environment, you might, take some of the investment you put in this area and put it into the areas where you had no capability. So the idea is that depending on what question you're trying to answer, you can use the same framework to tell the story about, what direction you think your organization should go. So finally, I'll leave you with this. This is a project that we open source to collaborate with the industry on. So I'll close out with, how to get involved with the project if you're interested in it. You can ask vendors, what defend techniques they support when you're making an acquisition in this space. And by thinking in terms of digital artifacts and defensive verbs, you can start to answer this question. With this specific defend technique, we can detect these attack techniques. And then that tells the whole story about what specific function in your enterprise is is is dealing with a particular threat. Right? The knowledge base, again, is available at defend dot mitre dot org, and we've published the ontology on that page as well. And it's, it's an OWL two format, and people can download it and extend it as they see fit. And we're looking for contributions. So if folks wanna add to it, they can send us an email at defend at mitre dot org, and we'll be very happy to engage with you. So thank you for the opportunity to speak here to you all, and, I look forward to your questions.",
  "language": [
    {
      "id": "http://vocab.getty.edu/aat/300388277",
      "type": "Language",
      "_label": "English"
    }
  ],
  "created_by": {
    "id": "https://example.org/cdkg/Creation/presentation/11",
    "type": "Creation",
    "caused_by": [
      {
        "id": "https://example.org/cdkg/Activity/presentation/11",
        "type": "Activity",
        "_label": "Presentation of \"Introducing D3FEND: A Knowledge Graph of Cybersecurity Countermeasures\""
      }
    ]
  },
  "digitally_carried_by": [
    {
      "id": "https://example.org/cdkg/DigitalObject/recording/11",
      "type": "DigitalObject",
      "_label": "Recording of \"Introducing D3FEND: A Knowledge Graph of Cybersecurity Countermeasures\""
    }
  ]
}