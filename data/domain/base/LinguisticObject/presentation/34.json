{
  "@context": "https://linked.art/ns/v1/linked-art.json",
  "id": "https://example.org/cdkg/LinguisticObject/presentation/34",
  "type": "LinguisticObject",
  "_label": "Textual content of \"Modelling regulation requirements using SHACL\"",
  "classified_as": [
    {
      "id": "http://vocab.getty.edu/aat/300027388",
      "type": "Type",
      "_label": "Transcript"
    }
  ],
  "content": "So it's my great pleasure to, introduce Veronica Heimsback, if if I pronounce that correctly. Heimsback. Yep. Okay. Senior consultant in, data science and AI, insights and data at, Capgemini, who will be talking about quite a hot topic in our space, shackle. So over over to you, Veronica. Thank you, James. Okay. Hello, everyone, and welcome to this talk on how we can model requirements described in regulations with the shape constraint language. My name is Veronika Heinspak, and I'm a senior consultant at Capgemini in Norway. I live, right outside of Oslo with my fiancee and our two children, three year old Edward and one year old Oda. I got my degree from the University of Oslo with a specialization in logic and semantics. And, of work experience, I've been touching into stuff like, writing kernel models in c to semantic technologies applications in Java. I started off as a developer, but in two thousand and nineteen, I joined Capgemini. And here I am working as a semantics nerd, information architect, and advisor. I have worked in several different industries, including oil, life sciences, public data, library, and media. I started working with Chacol in two thousand and sixteen, and, yes, that is before it became a standard. And, as all nerds, I have way too many hobbies, like, making stuff, hunting, board games, and teaching kids to code to name a few. So my current client is the Norwich Maritime Authority, and, all the examples you'll see today are actual data from our current project, simplified for the sake of examples, of course. So let us have a look at our simplified workflow of the semantics in the project. We have several different regulations in both Norwegian and English as PDFs or plain text. And, some monkey read me identifying concepts and relationships using my highlighter pen in order to transform the data into an owl light ontology that works as a term bank. So it could just be a discourse taxonomy, for example, and shackle constraints for detailed instance modeling. We have a sparkle query library that the back end use for information withdrawal that goes through some processing before it's pushed to the front end application. And currently, we have two projects running in parallel at the NMA. The first one is called APS. And, a brief description of that could be automatic detection of requirements connected to certificates for sailors. And the second one is called ET for short, which describe metadata for requirements and make use of the graph as an information lake to ask for specific questions connected to the requirements. An example of a question could be, my fishing vessel is eight meters long, and it's built on January third in nineteen ninety eight. Give me all requirements that apply for me in or order to operate in a regional waters. In this talk, I'll show you examples from the APS project. So let us say we have a sailor that wants to become a master mountaineer. There are then two things you can do. First, you could use the sparkle library to find all requirements needed for the master's minor certificate. This information is found in the shapes in combination with the owl light ontology. And secondly, we could take the sailor's CV and requirement shape for this certificate, the master Maynard certificate, as input. And output will be either conforms true if and only if he fulfills the requirements needed for the certificate or confirms false if it does not. If the output confirms false, you'll get a report from the shackle engine telling you what, the instance data, the sailor's CV, is missing in order to achieve this certificate described in the shapes. So the data can look like this. And this is the regulation text. It's a plain text file where someone must identify classes, relationships, and data values by hand at the moment. This is me and my highlight highlighter pen reading the region regulation text and using the English version of the regulation to translate on the fly. We do actually have a proof of concept running right now to see if it's faster to identify these entities with natural language processing techniques. And I'm quite sure that NLP is much faster than me reading stuff in an unknown domain as I had no prior knowledge or maritime data before I joined this project. So there's a there have been a lot of funny misunderstandings of terms and concepts. So we're going to model things like this. So here we see paragraph twenty eight part two, and it content describes requirements for gaining a master's minor certificate. And it says, in order to be issued a competency certificate, decafusser class one, that's the master millionaire, In addition to the requirements in paragraph twenty three, twenty four, twenty five, twenty six, and twenty seven, a minimum of thirty six months seagoing service as a responsible deck officer on seagoing ships with a gross tonnage of more than five hundred is required. Seagoing service is reduced to twenty four months if at least twelve months are earned as a chief officer on a vessel of gross tonnage five hundred or more. Long sentences. Anyways, as we see, there is a lot of information we want to keep from this short snippet of text, and there is also alternatives described here. The first alternative is minimum thirty six months as a deck officer, where deck officer is a superclass for all kinds of deck officer positions. The second alternative is minimum of twenty four months as a deck officer, where at least twelve of those is served as a chief officer. And chief officer is a subclass of deck officer. So how can we handle alternatives that includes a lot of different combinations and relationships? If we were to model this with the web ontology language, we sure would have to touch into owl axioms and restrictions at some point. We also need to know if data is correct, especially when we are to compare instance data with regulation requirements. And AL can only infer new facts in data, but it can't discover missing facts. And being able to understand OWL axioms and how our interpret data, you will need some understanding of discrete mathematics and logic. Well, my client are seafarers. Even though some players at the anime are trained in RDF, that does not mean we should throw high complexity at the table just because we can. The data owners here are experts in their domain, which is different and not in semantic technologies. The main language we then chose for a graph is the shape constraint language, a language designed for validating RDF under a closed world assumption. Unlike OWL, you can confirm data to given data constraints with Jekyll, which gives us the opportunity of checking a sailor's CV against the set of requirements to see if it fulfills a specific certificate or not. And, the shape constraint language are built up by shapes. And a shackle shape is a collection of constraints for a given RDF resource. We have two kinds of shapes in Shackle. The first is a node shape that describe constraints about focus nodes, usually the subject of a triple, and property shapes describing constraints about predicates and object values of a triple. The definition of a node shape is that it is a shape that is not the subject of a triple where path is the predicate. In this example, we see a vessel shape that has a constraint on target class vessel. So all constraints following in this shape will have to do with instances of the class vessel. The definition of a property shape is that it is is a shape that is the subject of a triple that has path as its predicate. In this example, we see a length shape with some path to vessel length. So for every occurrence of the predicted vessel length in any data, the constraints described here will apply to that triple. We can add property shapes onto a node shape using the resource property. Here we combine our true, previous examples stating that any instance of the class vessel may have some relationship called vessel length pointing to, in this case, some random object value as we haven't any more detailed constraints in the property shape. So there is a lot of constraints available in the Shackle core constraint vocabulary, and here is a brief overview of the main categories. And the nice thing about Shackle is that if you don't find a suitable constraint for your problem, you can extend Chackle with your own constraint definitions and push them to the web for others to reuse if you like. This is not possible to do with OWL as the OWL vocabulary is limited to those resources set by the OWL committee. And, Schectel contains constraints about, value types as class affiliation and data type values, cardinality as min and max count of predicates, value range as min and max inclusive and exclusive, string based as language checking, regular expressions, and length, property pair, comparing the object value of two predicates, logical constraints as not, and, and or, Shape based as the property relationship, we have just seen an example on. And there is also a collection of other constraints that doesn't fit into any of these other categories. And, there do exist more categories apart from the core, like sparkle constraints and check the advanced features, but I will not cover those in my talk today. I can post the link for the shackle master class that was hosted yesterday. There are some links to resources and references on things beyond sparkle core available there. So the main reason or one of the main reasons we chose Shackle was because of the extensive Shackle core constraint vocabulary and being able to extend that that if needed. Being able to model requirements containing alternatives as easily recognizable and and or constraints is a great benefit for us at the anime. Another reason is the verbose description of constraints that makes it easier for non semantic players to read the turtle files. Unfortunately, there is no currently no open source tool, at least to my knowledge, that let us visually create shackle constraints as protege a does for OWL. I know it exists a shackle plugin for protege, but as far as I know, or at least last time I tried to use it, it was, only a circle code view inside Prodigy and not the visual modeling tool that you know Progyny as. So we would have to stick with our editor of choice if we want to keep it open source. And Chackle is a validation language under closed world assumption, meaning that facts that are not known to be true are false. And this is necessary for us in order to say something about our case for comparing CVs to regulation requirements. So let us take this example snippet from the regulation. How can we easily express the requirement that a vessel shall have a gross tonnage of at least five hundred wells? Like, this. And here we have a property shape describing constraints for a given predicate. The predicate in question is the value of half, which is Gross Tonnage. We have a constraint that in a triple where gross tonnage is the predicate, the object value shall be minimum or equal to five hundred. We also have a constraint telling us the data type of this object value, which is unit g t, and a min and max count of one. That means that the predicate is unique and mandatory for resources where it appears. If vessel has a relationship cross to some value, this specific relationship shall only appear, once, at least once and not more than once. And here we see our solution on how to model the alternatives described in the regulation. As we remember from paragraph twenty eight part two, there were two different alternatives. There are also, some other options included in this or constraint, and I'm going to talk you through it. So the or constraint is a list taking constraint that appears at the predicate position of a shape. This or constraint takes in two and constraints as its list elements. The first and constraint are the first alternative. It takes in two items in its list. First, a or list of courses. So at least one of these courses, courses must be present for the whole expression to be valid. No. Not courses. Sorry. It's certifications. So the list of certifications. So at least one of these certifications must be present for the whole expression to be valid. And secondly, a specific value for a seagoing service, And we'll have a look a closer look at this seagoing service, later on. The second and constraints are the second alternative. It takes three items in its list. First, a or list of certificates, and then a specific value for a seagoing service, and another specific value for a seagoing service. We remember from paragraph twenty eight that the, second alternative was twenty four months as, some in some position, where at least twelve of those months were in another specific position. And that is described in this second and constraint. So let us look at the rest of the requirements in the snippet. We have information about duration, position, and a seagoing relationship, which can be some kind of trade area, the gross tonnage, and the gross tonnage that we saw in the previous example. And here are the requirements on the previous slide that described as shapes. The first shape is similar to the one for gross to Nash, describing a minimum or equals constraint. The second, state that the predicate in position shall be any instance of a decoder position. At last, we have a property shape describing the predicate trade area to have a specific value of bank phishing. The plus hierarchy with labels and relationships is found in the owl light ontology at the moment. However, this information could as well be in the shapes instead. At the NMA, they already had a few owl ontologies for their domain when I joined the project, but they struggled a lot, with how to model the alternatives described in the regulation and applying information like mean inclusive and data values. And that is another of the main reasons why I proposed model requirements in Chacel as it is so verbose and concrete. And for this case, on comparing CVs and regulation requirements, it's also the perfect case for Shackle validation. So let us put it all together for our first alternative in paragraph twenty eight part two. We have a node shape describing the class value of this first alternative using the property shape constraints that we just saw. And some good good annotation, shape description is a must. And then we target the class that represent the first kind of seagoing service described in the paragraph, which is the the value for target class. And at last, we connect the necessary property shapes with constraints that apply to this kind of seagoing service. The constraints for duration, position, trade area, and gross to match. So what Checkl really does for our models is it allows us to model data with a closed world assumption. This means that we strive for completeness of our data, and we do not admit that we have any incomplete knowledge in our regulations. And that is the whole point of a regulation, isn't it? A regulation is a set of requirements for one specific subdomain of maritime authorities in the region waters in this particular project. And it is important to remember that with the web ontology language and the open world assumption, we can describe broader and more unknown domains that makes it easier to apply ontologies across various applications and domains. However, even though shackle under a closed world assumption is probably most powerful locally, it is possible to reuse and share constraints across several application, especially in combination with existing ontologies using them as a reference for your constraints. If you're reusing shackle shapes from another application, you have the possibility of deactivating shapes that it's irrelevant for your application and add new ones that apply in order to extend the shapes graph you're reusing. With shackle, we can handle any constraint. And if we don't find what we need in the shackle core, you can simply add it yourself. You can even push your new constraints to the web for others to reuse. And shackle is verbose and gives us detailed explanation of requirements, which is really handy for players with limited experience with RDF. And again, OWL and RDFS are splendid on inferencing missing facts. However, it is not detecting missing data, and that is what we need. Would would you like to go over to questions now? Sure. You'll be pleased to know it's been relentless, the, the number of questions. So I'll try and rewind back to some of some of the earlier ones. What are the hardware requirements to use Shackle as a validation language? Do you need a reasoner, data storage, etcetera? It depends on your application and what you already have, but, you can do Shackle validation in memory if you like without, having to use a graph database. So, you have several different shackle implementations ready in frameworks for programming languages as Java, c sharp, and Python. I'm most familiar with the Java frameworks, and I know that the the two most popular frameworks, which is RDFJ and Jena, doesn't support the full shackle implementation yet. But it's possible to use it for for the most popular constraints in the shackle core. And by using a programming framework, you won't need a database. There is also shackle implementations in graph databases. As StarDog, they have a implementation of the shackle core constraints. And also, top quadrant actually have a full shackle implementation, including the shackle advanced features. And that is probably because one of the employees at Top Quadrant is, one of the leading developers on this standard. Yes. Apart from that, I don't know if I see there was a question on Neo four j or AVS Neptune. I'm not familiar with, if Neo four j has an implementation of Shackle. I'm not sure because Neo four j is operating on other data than than RDF. It's on labeled perfect graphs and not semantic knowledge graphs. But I know they try to map their labeled property graphs onto RDF and vice versa. So if there exists some shackle implementations in Neo four j, I don't know, but it would be funny to see. Yeah. I shared, I shared a link. So they have they have an implementation of shackle, but I think it's it relies on transforming RDF to label property graph, and then it's, it's part of an internal kind of Java plug in, I think, some of the validation functionality. There was a question or some points around shackle c versus shackle. I'm not sure whether that's a thing maybe might want to elaborate on. I don't know whether that makes any sense. I'm not familiar with shackle c. No. No. No. Not me neither. I'm sorry. It's a typo. Okay. It was Yeah. It it may look like shape expressions that, has been kind of a schema language for RDF prior to Shackle, but I'm not too familiar with that. So, someone Yeah. Someone commented Shackle compact syntax is Okay. Okay. That's that's his one. That has to do with Jason Aldi probably because that can be compacted quite a bit. Okay. There was another question, about whether it's possible to model you may have already answered this, but, whether it's possible to model shackle constraints completely via sparkle queries. Yes. All shackle constraints can be translated to sparkle at least. And I'm not sure if you can do it the other way by constructing shackle from sparkle. I haven't tried it. But in the shackle documentation, on the w three c domain, every single shape constraint has a, a sparkle definition as well. So So you can go in there and look on the sparkle definition for every single constraint. I'm sure it probably is possible to turn it the other way around as well if you want to construct shapes using, sparkle. Okay. Great. There was a question also from, Vladimir Alexiev, asking, Veronica, have you considered generating shackle from a briefer logical notation? Your rules are reminiscent of prologue. No. I I haven't considered that, but, I'll, bear it with me. Thank you. Cool. Maybe maybe you guys can, connect in the, in the Slack channel. Yeah. Great. Are there, any other questions? I can see a few people typing. So, I'll just check back through the history of the questions whilst that's those are coming through. I guess whilst, whilst those questions are coming through, I, yeah, I have a real affinity for the the kind of language challenge in, shipping. So we, we do a lot of work. My company does a lot of work in shipping. And the the language the language is particularly unique, isn't it? And there's very little in the way of kind of industry standards, particularly kind of ontologies or at least from from what we've found anyway. So I guess I was interested in how you're applying Shackle for kind of unstructured versus structured data, whether you're using Shackle for you touched on kind of maybe some opportunities around NLP and, Yeah. Yes. The NLP proof of concept was started because I didn't bother to spend too much time on reading the regulation text. It's about, I believe, around seventy regulations in the Norwich marathon sources. And, translating manually one text to anthology or two shuffle shapes by hand took probably around a week. So that's time consuming and expensive for my client. So we wanted to try out to see if we could make use of some simple NLP techniques to, draw information from the text. So we have actually successfully generated all scope descriptions and requirements descriptions connected to those scopes. And one scope could be like a a value range for vessel length or a date before and after one certain date or machine power. And a lot of different things are scopes in in the text. So we successfully do that now. And, the most challenging task around that is classifying entities discovered in text to be of kind material or construction or equipment and stuff like that. And so, yeah, the the proof of concept is still running. It's supposed to be finalized during December, and, hopefully, we will get the result that we want, which is the the class hierarchy or taxonomy, including labels and the the the shapes describing requirements and and scopes for the data.",
  "language": [
    {
      "id": "http://vocab.getty.edu/aat/300388277",
      "type": "Language",
      "_label": "English"
    }
  ],
  "created_by": {
    "id": "https://example.org/cdkg/Creation/presentation/34",
    "type": "Creation",
    "caused_by": [
      {
        "id": "https://example.org/cdkg/Activity/presentation/34",
        "type": "Activity",
        "_label": "Presentation of \"Modelling regulation requirements using SHACL\""
      }
    ]
  },
  "digitally_carried_by": [
    {
      "id": "https://example.org/cdkg/DigitalObject/recording/34",
      "type": "DigitalObject",
      "_label": "Recording of \"Modelling regulation requirements using SHACL\""
    }
  ]
}