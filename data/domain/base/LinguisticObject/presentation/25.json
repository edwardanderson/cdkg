{
  "@context": "https://linked.art/ns/v1/linked-art.json",
  "id": "https://example.org/cdkg/LinguisticObject/presentation/25",
  "type": "LinguisticObject",
  "_label": "Textual content of \"Graph Algorithms & Graph Machine Learning: Making Sense of Today's Choices\"",
  "classified_as": [
    {
      "id": "http://vocab.getty.edu/aat/300027388",
      "type": "Type",
      "_label": "Transcript"
    }
  ],
  "content": "Hello. I'm Victor Lee, vice president of machine learning and AI at TigerGraph, and I'm here today to talk to you about graph algorithms and graph machine learning, making sense of today's choices. So what is graph machine learning? You may have heard several things about it. Of course, we start with graph algorithms, knowledge graphs, which have both been around for a long time. Now we hear about graph data science, graph embeddings, graph neural networks. Maybe you know what these team terms mean. Maybe they're less familiar to you. But even if you know them, how do they all fit together? What are the use cases? How should you orchestrate these into some real world use cases? So we're gonna be going through some questions in this talk. Does graph machine learning replace graph algorithms? What is a graph embedding? What's the difference between graph neural networks and conventional neural networks? What are the use cases for these methods? And lastly, what setup do I need to run graph machine learning? These, we hope, are maybe some of the questions that you have, and we'll be addressing them in this talk. So the first thing to remember is that there's more than one type of machine learning. So first of all, we have unsupervised machine learning, which is very data driven. You you just look at the data you have, and you run some automated, analytics to try to uncover interesting things, relevant things, characteristic of that data. You're not you don't know what you're looking for. You just let the data itself tell you. And graph algorithms are an excellent example of unsupervised learning. So in that way, graph algorithms apply to machine learning. Then there's supervised. When people talk about ML, they're actually usually talking about supervised learning, particularly deep learning and neural networks. And so there's usually some, particular aim, like you're trying to make predictions based on some existing data. It's tied to classify objects. If I if I don't know what type of thing this is, can I use previous examples to develop a a model? Think of decision trees. Decision trees are an example of of a model which classifies something. You answer some questions, yes or no, and it eventually gives you an answer and says, oh, you are this type of thing or you should do this. It's it's putting you into a class and learning what well, what are the questions you we should ask in the decision tree. Sometimes you use machine learning for that. And there's reinforcement learning. That's when you just try a task and you're gonna make mistakes, but you learn from those mistakes, and eventually, you learn how to do it really well. So graph can apply both to unsupervised and supervised and and reinforcement. We're gonna focus primarily on supervised learning in this talk. It's also good to look at a typical pipeline or workflow for doing machine learning because this will tell us at what stages and in what ways graph can help. So first of all, at the beginning, when you're just gathering your data and assembling it, you made a a decision, presumably, to model it as a graph. Since we're talking about graph machine learning, we've gotta start off with a graph. So if you've made the decision that the relationships, the connections that you can express in a graph are that added, density of information, I call it. So more understanding how things are connected to each other is often what you're trying that's the nature of understanding data. And so, that's the first way it contributes. The second is kinda cleaning up your data, making sure that things are represented in a standard way, representing things that, might appear as different objects in the original data are in fact the same real world object. That's entity resolution. Trying to find those, making those matches of of different identities that are in fact the same. You can use graph based techniques for that. And when here in the middle, this is the core section where, traditionally, graph has played a role in machine learning. Using graph based features either through either through standard algorithms or writing specific pattern matching queries that that you designed for for your application. And this is all in the data preparation phase. And then we get to the model training. And and this is model training is when people talk about machine learning. That's, again, usually what they're thinking about. And now we have graph neural networks where if you have graph data, you can train directly on that using a graph neural network. So we'll talk about that. And then we have graph embedding. And and, again, that's one of the terms we're gonna define, and I've intentionally put it in between feature extraction and model training because it has aspects of both. So we have answered the first of our questions. Does graph machine learning replace graph algorithms? No. It doesn't because they contribute in different ways. Graph algorithms are great during the the feature extraction and feature engineering phase. They can also be used during the the data cleansing phase. But then you use graph machine learning is really the whole scope. But if you wanted to think of it as just the graph neural networks, then that is a a later stage that comes after you probably use the graph algorithms. So then looking at that pipeline, we saw about four stages where graph can can contribute. So we're gonna talk about each of those phases. The first being graph assisted data cleansing and entity resolution. So one thing that graphs are really good at is is identifying how things can be similar. And in this sense, let's talk about this. In this example, we have persons represented by these larger orange vertices, person a, person b. And then features or characteristics of them are represented by these blue vertices. And think about, say, x might represent a school, a particular school, And this relationship means person a went to school x, and this means person b also went to school x. So they have something in common. We y might be a city they grew up in or a place where they work. Other things they have in common. And so there's a reason why these are because, a city or a school are entities in themselves. That's why they're represented as vertices in the graph. And so there are a variety of similarity algorithms that can be used to compute a score based on this graph structural similarity of a and b. One example is cosine similarity. It takes into account the weights of these relationships and which ones match. And so the score is gonna depend on the weights of these x and y that match, but, divided by the existence of all these other factors whether they match or not. That's one way to come up with a score. And once you have these scores, you can represent them on the graph. And this means that, this group, they all have similarity scores in the nineties. This group, they also have similarity scores in the nineties, but c to e is only sixty five percent, d to f is only sixty percent. So those are lower. We can then do some scores together. If these each represent persons, that may mean of these seven original digital identities, that may mean of these seven original digital identities, we've reduced them or resolved them to two real world identities, Barry Markham and Beryl Markham. So that is, one way that we can use graph for machine learning. Another way is to help develop graph based features using either algorithms or pattern matching. And there are lots and lots of graph algorithms. This is TigerGraph's current graph algorithm library with about fifty algorithms, but they're even more. So we're always developing more. And they each have their different uses. The first thing you wanna do is understand the general type. Is it the similarity algorithm? Is it a centrality algorithm? Is it a community algorithm? And then there are different varieties among those. And then they those all lead to different uses. So here's just one example. And say you're trying to do some, data preprocessing to help predict, fraud. And so in this data, we have different application programs and then which have personal, identifying information. So this is your private information, which you don't want unauthorized persons to see. And by informing this graph, we can see that there's a cluster here, and there's a cluster here. And so and then we we apply a a community detection algorithm like Louvain. And then we move on to the next step when we apply other graph algorithms to each of these communities to score them, so to speak. So we have page rank. We have, LCC, another community detection algorithm, and diameter estimation, which has to do with, like, what are the shortest paths to get from anywhere to anywhere. So the diameter is the so called worst of the shortest paths toward the longest of the shortest paths. So we come up with an average page rank score, an average LCC score, and the diameter of each of these components. And you see, like excuse me. These scores, you can think of, they're numeric, and there's a set of them, and you can put them in a particular order. And, hey, that's a feature vector. So you now have a feature vector to describe this community. You can then put that into, machine learning algorithm to train it to detect which communities represent ones with fraud and which ones not. Because fraud tends to happen fraud is an interaction activity. You don't do fraud in isolation. It's always somebody interacting with somebody else. That's just one example. This was taken from a presentation that one of my colleagues presented. So if you wanna find out more, you can find other use cases from this presentation. It's not always standard algorithms, but sometimes it's it's designated pattern matching queries that you wrote for a specific application. In this application, we have phones and phone calls between the phones to form a graph. And the the phone service provider, the telephone company, is trying to do some automated real time detection to see if the phone call is is from an an annoying unwanted caller, a spammer, somebody who is, you know or maybe running some kind of scam. And so we extract we design several. In this case, several means a hundred and eighteen different pattern queries such as, is there a pattern that's a a four hop loop? Is there a pattern of calls to people who were called frequently over a certain time window? Is there a pattern of people who were called and then call each other forming a little subcommunity within a certain time window. And each of these features produces a score. Maybe it's yes, no. Maybe it's it's how often that pattern occurs. And so you get a feature vector. And then using that feature vector, we can, again, train it to detect in which cases, are these is this caller, the hub caller, caller number one, the source caller, somebody who might be a spammer or a scammer. So that's the second way. Again, graph can help us with data cleansing. Graph can help us with the very important phase of feature engineering. And now we're starting to get into, getting into machine learning traditionally thought of, and into the the model building. So one of the challenges with graph machine learning is that the data is so rich. It expresses such a wealth of information that sometimes doing this analytics can be expensive. And, also, conventional machine learning techniques are based on matrices, not on graphs. So there's a difference in the data representation, and there may be too much information to conveniently handle. So enter embeddings as a possible solution. What is an embedding? That was one of our questions. An embedding transforms high dimensional data into a lower dimension. An everyday example is how do we represent our spherical Earth, our planet on a map? We all read two dimensional maps, but the world is three-dimensional. A local map seems not a problem because the the Earth is relatively flat in that small space. But when you look at the whole globe, we have squashed the globe onto a flat projection. And that projection is an embedding that is a transform from three d to two d. And so you preserve the important details. You may have, you know, have some error in some of the less important details. And you can see here examples of three different ways to map the the world onto a flat surface. So in the case of a graph, what we wanna do is we start with the original graph. We take into account all the edges, the structural relationship of the graph, but we wanna reduce that down till we just have individual vertex vectors. So if these are the, the seven vertices plus their edges, we now just have these seven rows, and each row produces a a vector of latent features. They're not features that you can really describe, but a key is that this is relatively compact. And so now we have tabular data, which is relatively compact, makes it amenable to traditional machine learning. And the the characteristic of these embeddings is that if two vertices have are structurally similar because they connect to similar things in the in the same quantity, with the same similar types of paths, the same type of things, then they will have similar vectors. You can use simple algorithms that compute the similarity between two vectors, like cosine similarity, and you can make recommendations. You can group them together if they're similar and do classification. So you can do fraud detection. Again, all the use cases that we had before, you can still apply. But we've transformed the data. We've made it more scalable. We've made it more compact, and we've made it tabular, which means that you can now apply traditional machine learning techniques. So, again, why you do it? So to get a dense tabular format, and to gather graph features without manual extraction. Oops. And is it suitable? It's it's better if your data is relatively stable because if the data changes, you will have to retrain it. So this answers our second question, what is a graph embedding? It's something that transforms this graph structure into a compressed tabular format. And we're now on to the the fourth way that graph can help with with machine learning, and that is graph neural networks themselves. And start with ordinary neural networks, a powerful machine learning technique to predict and classify. That's why they're so well known, so well used. And then we have graph, which is a great way to get insight through connected data. You can somehow combine these. You can get what we call a graph convolutional neural network. So you take the traditional, neural network data flow, and you insert an additional step called the graph convolution. And what the graph convolution is doing is if each of these nodes represents a vertex in the graph, and so we're trying to learn about each each vertex in the graph. We have a convolution step where we take its features, this vertices features, and combine it with the features of its neighbors. And maybe maybe it's an averaging. Maybe it's something a little more complicated than averaging. But in some way, you combine and or convolve, as they say, the features of this with its neighbors. And that's where the graph information is coming in, looking at neighbors. So combines the added insight from connected data with the modeling power of neural networks. And so you're actually using the graph structure doing during the training. It's not just a preprocessing step, but it's you actually use the graph during the training cycle. The basic one we talked about is for a so called homogeneous graph when there's only one type of node, one type of edge. If you're familiar with other types of graph neural network other types of neural networks like attention networks or recurrent networks, There are graph versions of those. There are also algorithms for heterogeneous graphs where there's more than one type of node and more than one type of edge. And what's better, there are now, three major open source GNN libraries. All, PyTorch has one. TensorFlow just introduced one. And there's one DGL deep graph learning, which is just for graph. And so you have several choices for open source libraries, all in all in Python, of course. And so why would you use a graph neural network? If you have a graph where graph structure is important and you have a task where a neural network makes sense, then you probably should consider using graph or neural network. So you don't need to explicitly extract graph features. The training will do that. As I've said, they're they're a well established software framework, because you're you're just using a neural network. It's in Python. You can use a lot of the the same infrastructure. And so that answers one more question, and we'll we'll sort of say what's the difference between a graph neural network and a conventional neural network. It's that convolution phase when you're taking the local graph structure into account during the training. And I said, we're just gonna say, we've talked about some use cases. There are lots of use cases. Don't have time to get into all of them. But, again, if if you have graph data, you can apply these. You're gonna get some benefit. The last question we're gonna look at is what setup do you need for graph machine learning? Learning. And here it's useful to again look at our pipeline. So first off, you're gonna want a graph database and, hopefully, a scalable one to to make sure it's large enough and performant enough for the task you need to do. Because you're gonna be doing some computationally complex or intense stuff. To do the data cleansing, you're gonna have to be able to do some queries and updates. So you wanna be able to, you know, update your data in the graph. And you're gonna need a graph algorithm library as well as a graph query language. You know, all databases come with a graph query language, but you want them which is flexible enough to express some of those patterns such as the one in that, unwanted phone call application we looked at. And lastly, you need the capability to run graph neural networks. So where are you gonna get these capabilities? Oh, one more. Graph embedding also. So all of these are or should be available within a database. Obviously, this is a database, and you wanna be updating the data in the database. So, ideally, you can, run queries, update, read, read, write, read, modify, write queries here. And in this phase, you want a graph algorithm library incorporated in your database as well as, you know, a graph query language can also extract custom features. For this last phase of model building, you know, traditionally, you would export your data to machine learning server, but it's becoming more common that customers are looking for in database machine learning. And why would they do that? It's because it simplifies and shortens the pipeline. You bring the data in. You do your feature engineering and data cleansing in database. You train in in in database. You deploy in database. So there's, you don't have the the time and expense of pushing data from one place to around to another, it becomes a much more data centered operation. You you bring the analytics to the database rather than moving the data moving the data in a physical pipeline. And so last, I think that that covers all of our points. So let's let's review. So graph machine learning and graph algorithms contribute in different and complementary ways to analytics and machine learning. So it's not an either or choice. What is a graph embedding? It's something that transforms the graph structure to a a more compressed and tabular format for compatibility, with more traditional machine learning. Or you can do graph neural networks, and you actually can use both, but probably you would either use a graph embedding with a traditional neural network or a graph neural network. And a graph neural network takes local graph structure into account during the training. And lastly, if you wanna take advantage of all of this, you're gonna need a scalable graph database with flexible graph querying and doing those read write updates. You're gonna need a graph algorithm library and either an internal or external graph machine learning library with the advantages of of in database machine learning where you can do the training in the database, are starting to become apparent. And, again, we we hit on a few use cases. There's so many more. So I'll just say they abound. And so thank you very much for your your attention, and I, hope you got something out of this talk. Thank you very much.",
  "language": [
    {
      "id": "http://vocab.getty.edu/aat/300388277",
      "type": "Language",
      "_label": "English"
    }
  ],
  "created_by": {
    "id": "https://example.org/cdkg/Creation/presentation/25",
    "type": "Creation",
    "caused_by": [
      {
        "id": "https://example.org/cdkg/Activity/presentation/25",
        "type": "Activity",
        "_label": "Presentation of \"Graph Algorithms & Graph Machine Learning: Making Sense of Today's Choices\""
      }
    ]
  },
  "digitally_carried_by": [
    {
      "id": "https://example.org/cdkg/DigitalObject/recording/25",
      "type": "DigitalObject",
      "_label": "Recording of \"Graph Algorithms & Graph Machine Learning: Making Sense of Today's Choices\""
    }
  ]
}