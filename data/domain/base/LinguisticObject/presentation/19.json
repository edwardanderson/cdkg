{
  "@context": "https://linked.art/ns/v1/linked-art.json",
  "id": "https://example.org/cdkg/LinguisticObject/presentation/19",
  "type": "LinguisticObject",
  "_label": "Textual content of \"The Enterprise Knowledge Graph\"",
  "classified_as": [
    {
      "id": "http://vocab.getty.edu/aat/300027388",
      "type": "Type",
      "_label": "Transcript"
    }
  ],
  "content": "Hi. I'm David Newman. I'm going to introduce you to enterprise knowledge graph capabilities. First of all, let me, describe this from a very high perspective. New frontiers and innovation require investments in new foundational building blocks. For example, the mapping of the human genome is a representation of a first of a kind model that's a prerequisite step in innovations. Secondly, novel technologies must be developed that know how to effectively exploit the model, such as DNA sequencing technologies that developed to exploit the mapping of the human genome, and their focus is on reintegrating fragmented parts of DNA so that novel innovations could emerge that reflect critical breakthroughs such as, the mRNA, vaccines for COVID, cancer genomics, personalized medicine. Similarly, in finance, we're doing the same basic process to innovate new capabilities. In this case, we're mapping the financial genome using knowledge graph models called ontologies, and new technologies have emerged to exploit these very powerful representational models. Knowledge graph technologies focus on reintegrating the fragmented parts of data. Examples of technologies, that we need to exploit for knowledge graph are graph and virtual graph databases, knowledge driven data catalogs, and data fabrics, and graph algorithms, and graph neural networks, just to name a few. And these will result in some new innovations, such as advanced ways of understanding, customer, customer three sixty, ways to better, solve financial crimes, make risk more visible to better manage it, improvements in regulatory compliance, and significant improvements in data management. Knowledge graph is really the way forward for data. So let's look at this chart. At the bottom are things that humans can understand, and at the top are things that machines can understand. In parallel is the expressivity of the information model. The more expressive the information model, the more powerful will its linkage and insights be. So let's look at this chronologically. So around nineteen seventy, the relational model, the prevailing model today emerged, which focuses on looking at, columns and tables, which describes, basically, information in terms of strings or numbers that are represented as attributes within entities, relational databases emerged in around nineteen eighty five. Fast forward to the twenty first century with the emergence of knowledge graph models and databases, we could look at this area as a subset of artificial intelligence known as knowledge representation and reasoning or ontologies, which looks at data as things and not as strings. So looking at this, graph, data is look is looked at as first class objects or nodes in the graph that are associated with other nodes in a graph that reflect relationships. That's what these lines or edges are, and more about that later. So around two thousand and twelve, knowledge graph models and databases were able to converge with machine learning where we can leverage new analytic capabilities in this area called knowledge graph completion, where the algorithms converge with the knowledge graph database can infer new relationships, new linkages, link prediction, classification, categorization in order to create new nodes and create linkages between these nodes to reflect new insights. And then we can further evolve forward around two thousand and sixteen with the emergence of graph neural networks, which represent the intersection of knowledge representation and reasoning with machine learning, deep learning, and natural language processing to generate what we would call knowledge graph embeddings or vectorized things, which are ways of representing, very concrete pieces of information alternatively in, numeric representation or vector representation so that it aligns much better with machine learning algorithms in order to apply, new techniques, new analytic techniques that can, understand and express data that would otherwise be represented in a more conventional database in order to gain new insights in very precise ways of clustering information. And this ultimately is, right now, a way for machines to understand information that humans could also understand. So knowledge graph really is a strategic capability that transcends relational data capabilities. So when we look at the prevailing relational data paradigm, one of the things that really stands out is what I would call it duality or dualistic, scenarios where the model is segregated from the physical model, which is segregated from the metadata, which is segregated from the data. These are all separate. These are all, nonintegratable. So this also results in, tremendous incongruency and fragmentation, which results in a lot of data management problems, a lot of, complexity, a lot of limitations in what the prevailing relational paradigm can, actually achieve in terms of what we really need to, to support the, you know, very complex data needs today. So the emergence of the knowledge graph paradigm positions us much better for the future because data, because the data the model around that data plus metadata plus knowledge are all linked and integrated together. So I call this nondualistic. They're not segregated. They're integrated in a way that allows us to connect data to knowledge about that data. It's connected through this new paradigm rather than segregated in a relational paradigm. So the ability to actually link knowledge to raw data, and I'll explain that a little further on, is a is a huge achievement. So linking the data to its model, to its metadata, and knowledge about that data is gonna stimulate some very new innovations and tremendous business value. Well, let's dive into first what a graph is so we could better understand what a knowledge graph is. So a graph is a unique form of data organization that describes networks of connected data. So we can look at this, example here of a network or a graph, which is reflected with nodes connected to other nodes by these lines, which we call edges. These are connectors. For example, we could say that person a is a node, person b, c, and d are examples of nodes. And we can label the edges, with the, predicate pays, and we could then get a visualization at a at a data structure that indicates that person a pays both person b and c, and b and c both pay person d. And this is a very powerful data structure that can be used to reflect, use cases such as, anti money laundering, payments networks, ways of better detecting fraud, technology asset management, where, again, the basic organization of the data for the use cases and network. So so the idea here is to use a data organization that better reflects the use case than alternatively slicing and dicing this into tabular views that don't reflect this holistic picture. So what is a knowledge graph? So a knowledge graph is a very highly expressive form of data organized in a graph, except that the knowledge graph allows us to describe concepts that describe the data itself. And this representation of concepts in a logical model is also known as an ontology. It's a way of representing knowledge and describing meaning. A very standardized form of representing ontologies in is a language called RDFOWL, and it's the global semantic modeling standard. It's the a modeling standard that's best used to represent knowledge graphs because it's of its expressivity, and it's linguistically aligned with how we think and speak. And, basically, what this will do is allow us to take unstructured content definitions and translate it into a structured form that not only humans can understand, but machines can understand. So as an example, we could describe a model where we have a customer, associated with a checking account and a credit card account, and we have this notion of this edge that we could label with the meaning has account so that this is very intuitively understandable to a human. We can describe concepts and other concepts and the and the linkage of these is what we would call a predicate. And these could be further defined in a very rich taxonomy where we could describe that checking and credit card accounts are kinds of accounts, and that checking and credit card accounts also have common behaviors or attributes. In this case, they both share common behavior that they will have transactions that associate to another first class object called the transaction, which will also have a fan out of relationships that describe the meaning of the transaction, that it's meaningful in that a transaction may reflect the purchase from a merchant, and it may reflect the purchase amount, which is some monetary value. And that this could be all again represented using a standardized common semantic language like RDFOWL that is also highly reusable, which we'll describe a little more, in a moment, and it's something that humans and machines can both understand. So a knowledge graph elevated to an enterprise level is an enterprise knowledge graph, and this is where the knowledge graph model, is standardized and is highly reusable across the enterprise, and it organically grows bottom up from use cases where new business elements and, business behaviors are represented in this model that has enterprise reuse reusability capability. And this also, positions us for, leveraging a common semantic language across the enterprise for better, data integration as well as for improved interoperability because this knowledge graph model leverages open web protocols. So essentially, we're superimposing the, power and behavior of the Internet across our data and the ability to link data and information in the Internet is very similar to how we link and integrate data across an enterprise knowledge graph. So let's take the model we described a little bit earlier, and we can now introduce data to that model where we can execute new transactions for in this case, a customer has a consumer credit card account where there are one to many transactions that all fan out to the same standardized description of data that reflects transactions, monetary values associated with merchants, and this fan out can further occur. Now with the semantic web, what we're doing is we're prelinking information together using the fan out of the, web of data that all aligns with a common conceptual model, and we can ask certain questions. So we may ask a, some information about a merchant, and we may ask for a given merchant, who are the customers across the enterprise that interface with this merchant even though some of the customers are domiciled in different lines of businesses. So for example, consumer credit card line of business may have different, databases than the consumer debit card line of business or the commercial card line of business or the business credit card line of business. But if these databases are represented semantically as graph databases, then we will be able to, engineer, federation and interoperability across these databases because we all aligned to the same common model and the same web enabled protocols where we could simply ask a question of a merchant, and that question will traverse these, web enabled interfaces and linkages over the web of data in order to basically, identify that the ultimate customers associated with this merchant can be identified even though they may be, stored in different databases across the enterprise. So we could better enable enterprise linkage using the semantic web, and the web protocol for advanced interoperability. So, one more, point I wanna make here is that knowledge graph can apply knowledge to data in order to infer new insights and relationships. For example, the concept of corporate control, Again, it's broken down into this notion of subject, predicate, object, which again is linguistically aligned with how we think and speak. So let's take this example. A corporation is an example of a subject, controls another corporation, predicate, and another object represents this concept of corporate control. And then we can weave more specificity into this concept by saying that controls majority voting shares is a kind of controls. We can add more specificity to subjects, predicates, and objects. And then we can introduce data and link it to the model where we could say that Global Bank, a data assertion, is a type of a corporation, and New York Bank is a type of corporation. Now once we've done this and this is actually a significant leap because within knowledge graph, data and the metadata around it and the conceptual model around that can all be interlinked within the web. So it's all operationalized. We can then say that Global Bank, a type of corporation, controls the majority voting shares of New York Bank. And then we can also introduce additional concepts that is majority controlled by, is the inverse of controls majority voting shares. They're the polar opposites of each other, and we could introduce this into our model. And now you can see we're introducing some knowledge into the model by virtue of how we introduce concepts. And then we may be able to say that New York Bank, because it, is, has its major is controlled by Global Bank. Global Bank controls the majority voting shares of New York Bank. Therefore, New York Bank is majority controlled by Global Bank. We could draw that inference. And then we could further draw the inference that once we model that a parent company, and a subsidiary company have a relationship such that the subsidiary company is majority controlled by the parent company given that New York Bank must play the role of the subsidiary company, and Global Bank must play the role of the parent company. And these are very powerful inferences that we could make by linking the data to the concepts, establishing and defining knowledge about those concepts. And the knowledge really emerges when we draw these inferences to basically infer that Global Bank must be a parent company and New York Bank must be subsidiary company of Global Bank. And having this data linked to concept and knowledge is really a very powerful enabler and bridge to more advanced machine learning and the introduction of more precise, insights. So with that, I'm gonna turn the presentation over to my colleague, Omar Khan, to continue with his, part of the presentation. Thank you very much. Hi. Thanks for joining David and me today to talk about the enterprise knowledge graph. I'd like to talk a little bit about the current unlinked data environment and how adding linked data approaches will help with better integration with an easier infrastructure consolidation. So when you have a linked data environment, what that allows you to do is have various views so that you can have the view of the data if it's materialized, or you can have it run ad hoc. For example, if you see the banking data here, it's named with various different names and different silos for for Acme Widgets. However, when we go to take a look at the data in a federated view, what we see is we can pull these names together and work with them with ease without having to go across different systems. This provides you with a common query facade that you could use with RESTful APIs, SQL, SPARQL, or GraphQL. This could be used to feed a dedicated EKG. Moving on to the next slide. If you have an, enterprise knowledge graph, you could do something even more powerful. You could tie in question answering mechanisms where it uses natural language where you built a model that humans can use to perform inquiries. One thing I believe will be emerging is where instead of creating specific restful interfaces or other sorts of APIs, you will in fact be using a bot using natural language that will talk to the knowledge graph and get information out of it based off of question and answering models. Of course, there'll be security issues in which such coarse grained facilities exist. The other major benefit of having an enterprise knowledge graph is you could find out what sort of concepts are similar. For example, we had Acme Widgets Corporation, Acme Widgets, Acme Widgets Incorporated, and Acme Widgets Incorporated. They're spelled different ways, but the reality is they're equivalent to the same thing. In the previous slide, you saw we we had linked data that gave you the ability to perform federation amongst the data that exist. However, it didn't provide a model that gave similarity. It's true you could get a lot of value by by mapping and conventions. That said, what we could do is apply vector based models on top of the data, which would give us enhanced similarity. A lot of the recipe is taking relationships and text, creating chains of concepts within that the graph, and then seeing what is similar, making the matrix values that could be run with mathematical algorithms. So using graph embeddings and neural network based models would give you additional lift from the transformation. You want to be sure, though, to train the model correctly. My shirt says a clockwork onion. It should say a clockwork orange, but it says a clockwork onion. So the the the computer split this out wrong with a bad similarity model, or the human input the data incorrectly? It doesn't matter. You need to look at the data in the knowledge graph and the models, and that's example possible results. You could also perform all sorts of visualizations with your your with your knowledge graph. However, you probably don't wanna overwhelm the person who's looking at the graph with too much information. Instead, really focus on providing a user interface as meaningful to them and can be exploratory. There's a lot of tooling that provides data exploration and the ability to navigate the graph. However, typical end users are too busy to go through this sort of paradigm. Make the user interface clean and simple, and provide a selected slice of the graph that'll be meaningful to them. Also in the user interface, keep references to the knowledge graph to provide additional value. Thanks for your time, and I hope you enjoyed our presentation. If you're interested in best practices, please check out the Enterprise Knowledge Graph Foundation at e k g f dot org.",
  "language": [
    {
      "id": "http://vocab.getty.edu/aat/300388277",
      "type": "Language",
      "_label": "English"
    }
  ],
  "created_by": {
    "id": "https://example.org/cdkg/Creation/presentation/19",
    "type": "Creation",
    "caused_by": [
      {
        "id": "https://example.org/cdkg/Activity/presentation/19",
        "type": "Activity",
        "_label": "Presentation of \"The Enterprise Knowledge Graph\""
      }
    ]
  },
  "digitally_carried_by": [
    {
      "id": "https://example.org/cdkg/DigitalObject/recording/19",
      "type": "DigitalObject",
      "_label": "Recording of \"The Enterprise Knowledge Graph\""
    }
  ]
}