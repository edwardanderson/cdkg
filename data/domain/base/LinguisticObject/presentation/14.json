{
  "@context": "https://linked.art/ns/v1/linked-art.json",
  "id": "https://example.org/cdkg/LinguisticObject/presentation/14",
  "type": "LinguisticObject",
  "_label": "Textual content of \"Knowledge Graphs: Moving Beyond RDF\"",
  "classified_as": [
    {
      "id": "http://vocab.getty.edu/aat/300027388",
      "type": "Type",
      "_label": "Transcript"
    }
  ],
  "content": "Welcome to Knowledge Graphs, moving beyond archeo- RDF. My name is Kurt Cagle, and I wanna thank you for joining us this afternoon. A bit of a timeline, and note that these dates are only approximate. RDF, the resource description framework, was created in two thousand by sir Tim Berners Lee and others, others, pursuing an idea that emerged as he was developing HTML. With that language, he'd observed that hyperlinks, which connected a phrase or image in one document with a document elsewhere on the web, could be generalized to the idea of one concept or resource having a relationship with another concept in a conceptual space. This web of ideas, which you would christen the Semantic Web shortly thereafter, would end up driving the graph revolution of the twenty ten CVR. Originally, he used XML as the default language for this web, But over time, he realized that XML wasn't ideal for the task, even as he and others worked at the logical formalism language called the Web Ontology Language Language or OWL. By two thousand seven, SPARQL, an RDF query language, was produced to to querying sets of assertions using a new language called the Chirce RDF language, which hurdle, formally released in two thousand fourteen. Sparkle one point one was released about the same time, and it's worth understanding that Turtle and Sparkle have only just gotten started. This is very important as it effectively marked the end of the RKO RDF era. Turtle tends to get a lot of short shrift first from ontologists who grew up with OWL, RDF XML, and three notation and protege. And from those newer graph technologies who felt RDF XML and OWL were too complex or too dissimilar from the way that they were normally working with languages like JavaScript and Python. However, turtle as a language, has a great deal to recommend it. It is a much tercer language than RDF XML. Certainly, it's that's tercer than, m three. And arguably, it's JSON when namespaces are taken into account. Please see JSON LD. While OWL was built on XML, RDF XML can be very verbose and far from intuitive. Turtle is actually a surprisingly good language for expressing triples. It makes a good language additionally for prototyping or modeling objects. What's more, Turtle and SPARQL are largely complimentary because they essentially emerged in tandem. As Sparkle continues to evolve, so too does the expressiveness of Turtle. Indeed, I contend that part of the reason the turtle isn't used more widely is because it is a very young language, younger than JSON, and developed to express a very different need. Indeed, the primary limitations of Turtle as a language are simple. Turtle isn't JSON. We'll come back to this. It's worth dividing up the evolution of RDF into three distinct areas or eras. The first, the Archaeo RDF era was largely dominated by OWL, utilized n three for ingestion, a not very common format, and was built primarily for inferencing, a glorified word that means that it is possible to express new assertions by using logical operations on the existing graph or triples, then adding these back in as virtual triples. Serialization was primarily accomplished via fairly ugly XML representation. It appealed to academics, but was not very attractive to the woke up programmers out there. The Meso RDF era, on the other hand, began with SPARQL one point o, released in two thousand and seven, but took both the emergence of Turtle around twenty twelve and the beefing up of SPARQL in twenty thirteen to really take off. This was RDF's nuclear winter, where interest in the semantic web as an idea almost died even as significant new developments, the emergence of turtles, not mammals, were taking place. SPARQL one point one brought with it some significantly needed improvements that was still not quite sufficient. The SPARQL update facility was also introduced, replacing virtualized triples with formerly persistent ones, and the notion that you could query in a federated manner was introduced, although, again, not fully fleshed out at around the same time. Finally, we began to see the first upticks in the use of JSON as representations of troubles, especially in corporate environments with JSON LD linked data. It could be argued that JSON LD is possibly, probably, in fact, an evolutionary dead end, but it is signal signaled that the two communities were talking with one another. I believe we are in the beginning of the NeoRDF era. There are a whole host of new developments that last few years are beginning to coalesce, and that will likely be formalized within the next couple of years. This is not necessarily all where RDF is going, but it is what is most visible right now. I wish to cover each of these individually. The RDF role tends to spit out big, scary words. One of these is reification. A reification is a statement that describes another statement. For instance, let's say that you have a statement that specifies a relationship, a has route to relationship, between two airports in Seattle and San Francisco respectively. This description describes a route, and that route can have multiple properties such as distance in which airlines fly that particular route. Labeled property graphs, otherwise known as our LPGs, can can describe the first relationship but sputters on the second. With RDF star, first proposed in twenty seventeen, and Sparkle Star, a more compact notation for reification was proposed for both Turtle and Sparkle. This new notation makes a great number of operations much easier and goes a long way in making RDF graphs compatible with local property graphs. A second area where some exciting development is happening is in the increasing sophistication of property path languages, something familiar to users of both OpenCypher and Gremlin. With new ways of describing property graphs as first class objects and providing ways of specifying wildcards and variable bounds. Such a language could radically empower SPARQL to combine both inferencing and graph analytics operations into a single unified language. While there are several potential candidates for such a language, Shackle property paths look to be the most promising areas yet. This will be covered more when I talk about Shackle. Shackle, the shape constraint language, like most RDF technologies, was formulated in reaction to the emergence of turtle as the new face of RDF. Going through several iterations, it was finally approved in twenty seventeen. Shackle, ironically, is changing the dialogue about data modeling with RD web RDF away from the OWL specific sets of rules and formalisms towards a format that is more familiar to data modelers, application developers, and data scientists. In many respects, it is providing key in the integration of r d RDF with GraphQL as well. There is an active community now looking towards a SPARQL two point o implementation, building off of the previous implementation's weaknesses. Already, there are limitations pushing these boundaries by incorporating more sophisticated property paths, establishing functions, arrays, sets, and dictionaries as first class objects, fixing significant problems with lists and how they are managed in SPARQL, utilization of JavaScript like capabilities such as math map reduce type operators, lambdas or arrow functions, and template literals, and utilizing shackle to make JSON construction much easier. GraphQL is a good idea. While it is not part of the W three C stack that was originally developed by Facebook, It should be because it works very well with what RDF was intended to be. GraphQL has limitations. Reification is almost impossible to manage. The JSON data model is just not as robust at handling things RDF does well, including inheritance. And its hierarchical structure is at odds with the potential secret nature of graphs. But it is useful language for making RDF stores look like JSON stores from the outside world. Shackle is playing a big part of that, and almost every GraphQL bridge currently in production uses Shackle on the back end. With some changes to sparkle to make JSON, constructible directly from graphs, this could mark the merger point of these two query language technologies. Region. The twenty thirteen specification is a good start, but as implementations have been built, holes have become obvious. This will happen soon, probably within the next two years. Finally, it's worth recognizing that machine learning and graph technologies are in a collision course, and it is likely the next innovations will be the integration of these two, for everything from discoverability to better classifiers and more robust machine learning models. Thank you for listening. Please feel free to drop me an email or contact me on LinkedIn if you have any questions. Thank you.",
  "language": [
    {
      "id": "http://vocab.getty.edu/aat/300388277",
      "type": "Language",
      "_label": "English"
    }
  ],
  "created_by": {
    "id": "https://example.org/cdkg/Creation/presentation/14",
    "type": "Creation",
    "caused_by": [
      {
        "id": "https://example.org/cdkg/Activity/presentation/14",
        "type": "Activity",
        "_label": "Presentation of \"Knowledge Graphs: Moving Beyond RDF\""
      }
    ]
  },
  "digitally_carried_by": [
    {
      "id": "https://example.org/cdkg/DigitalObject/recording/14",
      "type": "DigitalObject",
      "_label": "Recording of \"Knowledge Graphs: Moving Beyond RDF\""
    }
  ]
}