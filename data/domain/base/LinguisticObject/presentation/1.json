{
  "@context": "https://linked.art/ns/v1/linked-art.json",
  "id": "https://example.org/cdkg/LinguisticObject/presentation/1",
  "type": "LinguisticObject",
  "_label": "Textual content of \"Applying Semantic Web Standards for Knowledge Representation at Elsevier\"",
  "classified_as": [
    {
      "id": "http://vocab.getty.edu/aat/300027388",
      "type": "Type",
      "_label": "Transcript"
    }
  ],
  "content": "Good morning. Good afternoon. Good evening, everyone. Welcome to the talk, Applying Semantic Web Standards for Knowledge Representation at Elsevier. I'm Veronique Moore, Manager of Taxonomy Development and the slide deck was prepared together with Anna Tordai, who is Senior Architect also at Elsevier. The outline will be quite short. First, I'll walk you through a bird's eye view what Elsevier is, from publisher to technology organizations, so what we used to do and what we are doing now, which will lead to the question, why do we need linked data standards? And then more importantly, what are we doing? We'll link data at Elsevier. I'll start at the global level, and then we'll do a deeper down presentation of how we use it for managing vocabularies. So Elsevier, maybe you know us as a publishing company, and that is still true. As in two thousand eighteen, we were still publishing four hundred seventy thousand articles, throughout the whole year. But even so, if we're publishing articles, we're adding, data. We're adding value to it. For example, the United Nations, sustainable development goals classification. So the articles are tagged, with these different goals, so you can see which articles, which research contributes to sustainable developments. The, funding references, that are also in the articles are tagged also. So a funding body can, look how many articles were published based on a a specific grant, and we add other values. So publishing, yes, but, doing data analytics on top of it. Elsevier is a global company with seven thousand nine hundred employees all over the world. Yeah, people in my team are working from Australia, for example. And our CEO is comes out by asset. So eighty three percent of our revenues right now comes from digital products. In a nutshell, who are we? We are global information analytics business, and we help scientists, researchers, students, doctors, nurses, engineers, a wide range of customers find actual answers to their most critical needs. And, one aspect in which we helped out, the past global pandemic was to build, a coronavirus research hub, where we helped out researchers, get quick and targeted access to, every research that we could tag that was relevant for coronavirus in terms of impact, or in terms of research. And this was declined in a whole set of tools that we provide at Elsevier. Mendeley, you might be aware of for managing your bibliographical records, but it also provides recommenders. So Mendeley data had a special COVID nineteen feature. Scopus and ScienceDirect are a publishing platform, so, you could be accessing the COVID nineteen relevant parts of these huge platforms. HyAxis, for example, is a tool that is targeting on chemical reactions. So if your domain is chemistry and you were interested in research around COVID nineteen within chemical reactions, you could access this spot. So that was into the, coronavirus researcher. The hub now is still available and the papers that were made publicly accessible via this specific hub are still accessible for research. So Elsevierian numbers. I'm not gonna go through all these numbers, but this gives you an idea of the volume of data, information, documents that we're dealing with. And, you can also see some of the different products that we're providing. So Sharepath is for nursing education. It's, a recommended system that helps, nurses get into their journey for, training and getting their, how do you call it, certificates. Clinical key, serves medical doctors, provides them access to clinical overviews and actual answers to questions they might have when facing a patient. So it's not only static data, but it's a lot of dynamic and on the spot data that, we also deliver through our products. And what is the big challenge in research? What is the big challenge for our customers? What do they need? They need data. And one of the big pain points is around data preparation, of course. It's time consuming, computationally heavy. We have lots of data, and data is coming in every single day. It's repetitive. It's not fun. Yeah. But it has to be done. It's like, bunny tight, like, yeah, loving you is a dirty job, but someone's got to do it. And it is brittle, if it's done in an ad hoc manner. What we need then, is to have pipelines that get data through standard processes, but that convert it into a format that is, easily curable because it's understand that it's understood by, the wide set of tools at Elsevier of our data platforms. What we need is standardization. What we need is link data. The same same problem, and, then we can hop on to the, great design model that the link data provides, because here too, there's, enormous number of datasets that appear every day that were created by different people, by different organizations. They talk about different type of datasets. They serve different purposes, but they're all linked. They're they're referenceable. They are standardized, and thus, they can be interoperable and standard QA. So quality assurance tools can be applied throughout. And pipelines can be designed to fit the global unified model instead of having, a processing So for that, the architecture team where Anatolia is, designed the Elsevier Linked Data Standard, which is a place where you can find references to, existing w three c, so World War Web Consortium, recommendations that we're using. It defines when we're using the recommendations as is and when, some specific model has been extended for our needs, because yeah. You'll see in the next slide. First, we start with the w three c models. So we're using a shackle, and it's a huge expressive power, for restricting and helping out auto populating some of the metadata around the vocabularies. In the management system, we use PROV and PAV to define the provenance of data, that we have there. So entities, it can be the provenance of a vocabulary, a provenance of a paper, a provenance of a given concept in a specific graph. So we can go at all sorts of different levels. But because we're using standard vocabularies, the semantics is defined in a standard way, and we can also interact with vocabularies that are external datasets that are external, and we know that they will be compatible because they use the same semantics. Vocabularies that I mentioned once or twice already, are designed in Scos and more specifically in SCOS Excel. And the annotations, that we produce follow the web annotation data model. So we're compatible and data can be used, by people who use other linked data. We can use other linked data, and this way we can interact with the latest progress in science. Because we have lots of very specific types of data, Elsevier has designed an Elsevier data model to be able to express information and relationships for these different types of entities. So here you see a quick snapshot, around reactions that would be for tools like reaccess, clinical trials, treatments, diseases, because, yeah, Elsevier focuses a lot on the health side of things, your drugs, patients. But there's also another side, which is, represented by funders, researchers, research institutions. So researchers and funding institutions are part of the people, we need to express information for, because they're interested in outcomes of what has been published. So that's part of metadata we add using standards. And a side that's not present in this slide is everything related to engineering and sustainable development, renewable energy, which is a big, growing facet. We have Vocabrio's ecosystem to support, these different products to support our customers, and we have a dozen vocabulary management teams across the globe. They are not all, yeah. It's not just one big team that serves everybody across the globe, but we have different teams that are spread up. And the way to, be able to interact and share not only vocabularies, sources, but also processes is to have a link data again and follow the same standards. So we follow the Elsevier data model, which is linked to international IDF standards. And that way, we can grow our data but benefit from each other also. So, we have two big knowledge graphs. We have thirty vocabularies and, of course, these vocabularies have some overlap and, of course, some new products, projects, proof of concepts, development need, new vocabularies to be built quickly. And, because we link them and we use the same semantics and properties across them, then we can spin off, yeah, some quick vocabulary or subgraph or branches based on what we already have and can share across the globe. The use cases that we serve are quite varied. It's basically anything you can do with the vocabulary. So browsing, autocomplete in Mendeley data, for example. Recommender in ScienceDirect, Mendeley. Classification, I was mentioning the, United Nation sustainable goals classification. There's also topic classification. We do annotation and search. And I will, talk more about annotation in a minute when I'll show you an actual tool and, yeah, an actual product that we produce, which is the ScienceDirect topic pages. So we have time for it, a little spotlight. What is a topic page? A topic page is, some sort of like a Wikipedia if you want but for scientific concepts. The idea is to give a researcher who doesn't know much about one specific notion a definition if we have it, related concepts or some sort of, yeah, cloud of related notions and relevant snippets from our content so that they could grasp what this notion is about and get resources to do a deep dive from there if they're interested in learning more. So, for example, you can access it using a Google search. So what is the cosine similarity distance in NLP gives you as first results, topic page or at least did at the time of this screenshot. Not certain it's still the case. From our content, from ScienceDirect, when you get an article, there's some annotation that happened, and, the hyperlink redirects you to the topic page. This is what it looks like. So here a definition would appear if it would have one for cosine similarity. And as you can see, the process is still a work in progress. So, we do try to populate definitions for as many pages as we can, and we are investigating more resources, yeah, and more sources for filling them in. There's a set of related terms, and here are the snippets I mentioned. So if you go down the page, you get book chapters that you can read, that gives you some information about what cosine similarity is, what its use, and there is a feedback box. So for example, here the feedback could be, there's no definition. I don't need a topic page if there's no definition. So that's good feedback for us to be spotting what are the critical places where we would need to, add data or information. In the back end, how does it work? Well, it works based on linked data because we need to, have a taxonomy, annotating all of science direct publications, but also book publication and all sorts of other tools. We also integrate with high access reactions. So on some topic pages, you can see reactions. We integrate with clinical key, to have medical recommendations also show up in topic pages. So there's an interaction, for a whole range of document type that used to be serving different products. So if you keep all the documents separate in the way they're processed, if you keep all the documents targeted to one single product, then you cannot build such an aggregation . So there is data mining from different sources that are aggregated using relevancy ranking to get the, topic page having the most, useful information, focusing on entry point information, about a given topic. And then there are automated scripts, but also a thorough SME review of the topic pages after every release. There's sorry. There's a quarterly release, of topic pages. So, four times a year, you get a new set of topics that are published. And the topic pages are using OmniSciences as a source for annotation. The OmniSciences is a Scos Excel vocabulary that was started in two thousand fourteen. Its first, use case, like, its first goal, was to link the different standards that we were already using for annotating content at Elsevier and, that needed harmonization, but also to be able to do, cross platform m and gams. So we created, we created Omniscience for that first purpose, but we didn't base it on the Elsevier standards themselves. We build it on linked data. So we used, DBpedia anthologies to see how the international community in research was representing the world of research. We use some principles as atomization of concepts, so that we could link out two vocabularies that regroup some entities in different ways. So for example, if Elsevier were classifying, articles, in agriculture and agrobiology and food sciences as one topic. We were creating three different topics to link out to these because other vocabularies might regroup fisheries together with, other concepts. So we didn't want to be relying on one specific grouping, but we wanted to have, only atomic entries that we could link out for making end to end crosswalks. As I said it's using ScosXcels. ScosXcel also for mappings. We keep external unique identifiers to be able to get back to the references , and we use provenance and, DCT source information to link our vocabularies and and keep in our vocabularies as much metadata as possible that we could use for either making a subset based on copyrights, of course, or, yeah, making crosswalks between two specific resources. So Omniscience was created as a bridge, and then it expanded. We needed one single single vocabulary for, the paper submission system, which at time was revised. And so we added to, the top levels that we had created using only broad levels of science scientific description. We added all the controlled vocabularies that we use for all the, individual journal submission systems that was now gathered into one. We went from, four thousand concept to fifty five thousand in two years. And now for, building the topic pages, willing that to a piece that is built on automatically extracted concepts from the back of the book index, from glossaries, and and other resources, and we're up to seven hundred thousand concepts. We use for crosswalks, classification, annotation, and recommendation. And, well, these are the fields of science that I covered. So medicine still represents twenty percent of omniscience because our content is still mostly targeting, yeah, health sciences and life science. But engineering and renewable energy or energy in general are moving into the, the proportion that went from one percent to, yeah, like seven percent or five percent. And I'm sure that it's still that the strand is still gonna, be followed. So the main challenge is how to grow, the vocabulary and keep it accurate because we want the topic pages to be, representing truthful information, but we want the topic pages to be on the latest, topics of research. So we need to have the latest information, and we need to be sure that it's put at the right place with the right set of, synonyms and the right set of relationship to make sure that the topic page wouldn't be, yeah, incorrect and not that useful for our customers. So we grow topic, we grow OmniScience based on, customers' communities, so mostly by, getting updates from, public vocabularies that are updated clearly or at a higher frequency. So we keep up to date with what most scientists are using as reference vocabularies. We, get feedback from our customers' needs based on search logs, and we try to make sure that these are covered. We also have system of extraction for the, trending and influential topics that are automatically extracted, from last month's research and curated by SMEs and placed at the proper place in the taxonomy. That would be a topic on its own to see how can we streamline the process of injection of new entries. And then product project needs. So, as I mentioned, topic page that I was doing in interacted with, Reaxys. So for this, linking between, two products or projects or use cases, we had to expand the taxonomy in the chemistry domain. So based on the, the global, products that we're serving, policy or roadmaps, let's say, we expand one branch or another. But for all of this, what we really want to do is to deliver data that is high quality data. So how do we make sure that we do have this? Because we are using linked data standards, we can rely on standard ways of QA ing. So whenever one of the twelve, taxonomy team develop a specific QA mechanism, we can apply it to other vocabularies also, And that saves us a lot of time and, and that allows us to share information and to produce standard standard reports also, not only standard QA procedure, QA pipelines, but but reports because we build it on the same tools and on the same models. So the taxonomy management system is based on a triple store and, so we're using RDF, SCOSXL, for representation. We're using Shackle's, expressiveness. For example, we have, regular expression based way of checking that a CAS number attached to a concept that is, a chemical entity is a correct CAS number. So if you're doing a typo, the system will tell it to you, and it's based on standard linked data technology. We use SPARQL for producing reports, subsets, and doing release type of global QA. We're using, yeah, pandas and an extension of pandas to doing batch processes because it's all tables and RDF triple based. We try to reuse as much as possible because we can do faster life cycles now that our taxonomies are not dedicated to a given product, but dedicated to some branches with a lot of metadata that allow, modularization and rebuild. And the publication is done also through a triple store where the, different customers can pick up the latest release. And, because we are publishing as a trig, so, all the sparkle and shackle, QA validation rules are part of the data model that is sent to the publication triple stored together with the data in a trig file, then everybody down the line has a self sustainable, unit of information that gives the semantics of the data together with the data. The publishing triple store has dereferencing and browsing UI for manual use, but also, of course, a lot of APIs and a sparkle endpoint for automatic interaction. So that is a glimpse of what we're doing with linked data at Elsevier, and I thank you for your attention. I'll be in the room for more questions. Thank you very much.",
  "language": [
    {
      "id": "http://vocab.getty.edu/aat/300388277",
      "type": "Language",
      "_label": "English"
    }
  ],
  "created_by": {
    "id": "https://example.org/cdkg/Creation/presentation/1",
    "type": "Creation",
    "caused_by": [
      {
        "id": "https://example.org/cdkg/Activity/presentation/1",
        "type": "Activity",
        "_label": "Presentation of \"Applying Semantic Web Standards for Knowledge Representation at Elsevier\""
      }
    ]
  },
  "digitally_carried_by": [
    {
      "id": "https://example.org/cdkg/DigitalObject/recording/1",
      "type": "DigitalObject",
      "_label": "Recording of \"Applying Semantic Web Standards for Knowledge Representation at Elsevier\""
    }
  ]
}